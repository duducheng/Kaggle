{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To improve Titanic accuracy\n",
    "### --By Jiancheng\n",
    "Work on [Kaggle Titanic](https://www.kaggle.com/c/titanic)\n",
    "\n",
    "Start on 2016/03/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "1. Data processing module changes\n",
    "1. Testing separate model on SVC, GBC, etc\n",
    "1. Voting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dtrain = pd.read_csv('data/train.csv')\n",
    "raw_dtest = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new features into data processing module:\n",
    "1. Delete 'Family' features, replace with the original features 'SibSp' and 'Parch'\n",
    "1. Normalizing the features on the training and testing data set\n",
    "1. Delete 'Title feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(in_df, mean_train = None, std_train = None, training = False):\n",
    "    df = in_df.copy()\n",
    "\n",
    "    age_average = {' Major': 48.5, ' the Countess': 33.0, ' Don': 40.0, ' Sir': 49.0, ' Miss': 21.773972602739725, \n",
    "                   ' Mlle': 24.0, ' Mrs': 35.898148148148145, ' Capt': 70.0, ' Rev': 43.166666666666664, ' Dr': 42.0, \n",
    "                   ' Master': 4.5741666666666667, ' Mr': 32.368090452261306, ' Ms': 28.0, ' Jonkheer': 38.0, \n",
    "                   ' Col': 58.0, ' Lady': 48.0, ' Mme': 24.0, ' Dona': 39}\n",
    "    title_convert = {' Major': 'Army', ' the Countess': 'Upper', ' Don': 'Mr', ' Miss': 'Miss', ' Sir': 'Upper', ' Mlle': 'Upper', \n",
    "                        ' Mrs': 'Mrs', ' Capt': 'Upper', ' Rev': 'Rev', ' Dr': 'Dr', ' Master': 'Master', ' Mr': 'Mr', ' Ms': 'Miss', \n",
    "                        ' Jonkheer': 'Upper', ' Col': 'Army', ' Lady': 'Upper', ' Mme': 'Upper', ' Dona': 'Upper'}\n",
    "    \n",
    "    # feature transformation\n",
    "#     df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df['orgTitle'] = df['Name'].map(lambda x: x.split(',')[1].split('.')[0]) # extract \"Title\" from \"Name\"\n",
    "    df['Title'] = df['orgTitle'].map(lambda x: title_convert[x]) # then also merge some rare Title into commom ones \n",
    "    df['Cabin'] = df['Cabin'].map(lambda x: str(x)[0])\n",
    "    df['Cabin'] = df['Cabin'].map(lambda x: x if x != 'T' else 'n')\n",
    "    df['Sex'] = df['Sex'].map(lambda x: 0 if x == 'male' else 1) # male: 0 female: 1\n",
    "    \n",
    "    # deal with NaN and 0\n",
    "    df['Fare'] = df['Fare'].groupby(df['Pclass']).apply(lambda g: g.fillna(g.mean())) # the average Pclass fare\n",
    "    df['Fare'] = df['Fare'].groupby(df['Pclass']).apply(lambda g: g.replace(0, g.mean())) # the average Pclass fare\n",
    "    df['Embarked'] = df['Embarked'].fillna('n')  # the most frequent item\n",
    "    df['Age'] = df['Age'].groupby(df['orgTitle']).apply(lambda g: g.fillna(age_average[g.name])) # average age of Title\n",
    "    \n",
    "    # normalization\n",
    "    if training:\n",
    "        mean_train = df[['Age','SibSp','Parch','Fare']].mean()\n",
    "        std_train = df[['Age','SibSp','Parch','Fare']].std()\n",
    "        \n",
    "    df[['Age','SibSp','Parch','Fare']]= (df[['Age','SibSp','Parch','Fare']]- mean_train) / std_train\n",
    "    \n",
    "    \n",
    "    # transfer category feature into dummy feature   \n",
    "    df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['Pclass'], prefix='Pclass')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['Cabin'], prefix='Cabin')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['Title'], prefix='Title')], axis=1)\n",
    "    \n",
    "    # drop features we don't need \n",
    "    df = df.drop(['orgTitle'], axis = 1)\n",
    "#     df = df.drop(['Embarked', 'Name', 'SibSp', 'Parch', 'Ticket', 'PassengerId', 'Pclass', 'Cabin','Title'], axis = 1)  \n",
    "    df = df.drop(['Embarked', 'Name', 'Ticket', 'PassengerId', 'Pclass', 'Cabin','Title'], axis = 1) \n",
    "    return df, mean_train, std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived        0\n",
      "Sex             0\n",
      "Age             0\n",
      "SibSp           0\n",
      "Parch           0\n",
      "Fare            0\n",
      "Embarked_C      0\n",
      "Embarked_Q      0\n",
      "Embarked_S      0\n",
      "Embarked_n      0\n",
      "Pclass_1        0\n",
      "Pclass_2        0\n",
      "Pclass_3        0\n",
      "Cabin_A         0\n",
      "Cabin_B         0\n",
      "Cabin_C         0\n",
      "Cabin_D         0\n",
      "Cabin_E         0\n",
      "Cabin_F         0\n",
      "Cabin_G         0\n",
      "Cabin_n         0\n",
      "Title_Army      0\n",
      "Title_Dr        0\n",
      "Title_Master    0\n",
      "Title_Miss      0\n",
      "Title_Mr        0\n",
      "Title_Mrs       0\n",
      "Title_Rev       0\n",
      "Title_Upper     0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_n</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_n</th>\n",
       "      <th>Title_Army</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.584059</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.515736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282790</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.406983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.499636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
       "0         0    0 -0.584059  0.432550 -0.473408 -0.515736           0   \n",
       "1         1    1  0.621016  0.432550 -0.473408  0.772917           1   \n",
       "2         1    1 -0.282790 -0.474279 -0.473408 -0.502152           0   \n",
       "3         1    1  0.395064  0.432550 -0.473408  0.406983           0   \n",
       "4         0    0  0.395064 -0.474279 -0.473408 -0.499636           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Embarked_n     ...       Cabin_G  Cabin_n  \\\n",
       "0           0           1           0     ...             0        1   \n",
       "1           0           0           0     ...             0        0   \n",
       "2           0           1           0     ...             0        1   \n",
       "3           0           1           0     ...             0        0   \n",
       "4           0           1           0     ...             0        1   \n",
       "\n",
       "   Title_Army  Title_Dr  Title_Master  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0           0         0             0           0         1          0   \n",
       "1           0         0             0           0         0          1   \n",
       "2           0         0             0           1         0          0   \n",
       "3           0         0             0           0         0          1   \n",
       "4           0         0             0           0         1          0   \n",
       "\n",
       "   Title_Rev  Title_Upper  \n",
       "0          0            0  \n",
       "1          0            0  \n",
       "2          0            0  \n",
       "3          0            0  \n",
       "4          0            0  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtrain = pd.read_csv('data/train.csv')\n",
    "raw_dtest = pd.read_csv('data/test.csv')\n",
    "dtrain, mean_train, std_train = process_data(raw_dtrain, training = True)\n",
    "print dtrain.isnull().sum()\n",
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      29.754659\n",
       "SibSp     0.523008\n",
       "Parch     0.381594\n",
       "Fare     32.876990\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      13.277179\n",
       "SibSp     1.102743\n",
       "Parch     0.806057\n",
       "Fare     49.690114\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest, mean_train, std_train = process_data(raw_dtest, mean_train, std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      29.754659\n",
       "SibSp     0.523008\n",
       "Parch     0.381594\n",
       "Fare     32.876990\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      13.277179\n",
       "SibSp     1.102743\n",
       "Parch     0.806057\n",
       "Fare     49.690114\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_n</th>\n",
       "      <th>Title_Army</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.357406</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.504080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.298871</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.520767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.428629</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.466682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.207473</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.487310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.584059</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.414358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex       Age     SibSp     Parch      Fare  Embarked_C  Embarked_Q  \\\n",
       "0    0  0.357406 -0.474279 -0.473408 -0.504080           0           1   \n",
       "1    1  1.298871  0.432550 -0.473408 -0.520767           0           0   \n",
       "2    0  2.428629 -0.474279 -0.473408 -0.466682           0           1   \n",
       "3    0 -0.207473 -0.474279 -0.473408 -0.487310           0           0   \n",
       "4    1 -0.584059  0.432550  0.767199 -0.414358           0           0   \n",
       "\n",
       "   Embarked_S  Pclass_1  Pclass_2     ...       Cabin_G  Cabin_n  Title_Army  \\\n",
       "0           0         0         0     ...             0        1           0   \n",
       "1           1         0         0     ...             0        1           0   \n",
       "2           0         0         1     ...             0        1           0   \n",
       "3           1         0         0     ...             0        1           0   \n",
       "4           1         0         0     ...             0        1           0   \n",
       "\n",
       "   Title_Dr  Title_Master  Title_Miss  Title_Mr  Title_Mrs  Title_Rev  \\\n",
       "0         0             0           0         1          0          0   \n",
       "1         0             0           0         0          1          0   \n",
       "2         0             0           0         1          0          0   \n",
       "3         0             0           0         1          0          0   \n",
       "4         0             0           0         0          1          0   \n",
       "\n",
       "   Title_Upper  \n",
       "0            0  \n",
       "1            0  \n",
       "2            0  \n",
       "3            0  \n",
       "4            0  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(model, data, cv = 10):\n",
    "    X = data.drop(['Survived'], axis = 1)\n",
    "    y = data['Survived']\n",
    "    model.fit(X, y)\n",
    "    training = model.score(X, y)\n",
    "    validation = cross_validation.cross_val_score(model, X, y, cv=cv).mean()\n",
    "    print 'Training accuracy:\\t\\t\\t', training\n",
    "    print '%s-fold cross-validation accuracy:\\t' % cv, validation\n",
    "    print 'Delta(training - validation): \\t\\t', training - validation\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t\t\t0.822671156004\n",
      "10-fold cross-validation accuracy:\t0.815950800136\n",
      "Delta(training - validation): \t\t0.0067203558683\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(RandomForestClassifier(n_estimators=300, max_depth=3), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on depth = 1=========\n",
      "Training accuracy:\t\t\t0.721661054994\n",
      "10-fold cross-validation accuracy:\t0.724038701623\n",
      "Delta(training - validation): \t\t-0.00237764662858\n",
      "=========Test on depth = 2=========\n",
      "Training accuracy:\t\t\t0.799102132435\n",
      "10-fold cross-validation accuracy:\t0.777997957099\n",
      "Delta(training - validation): \t\t0.0211041753364\n",
      "=========Test on depth = 3=========\n",
      "Training accuracy:\t\t\t0.802469135802\n",
      "10-fold cross-validation accuracy:\t0.794764215186\n",
      "Delta(training - validation): \t\t0.00770492061691\n",
      "=========Test on depth = 4=========\n",
      "Training accuracy:\t\t\t0.848484848485\n",
      "10-fold cross-validation accuracy:\t0.816138917263\n",
      "Delta(training - validation): \t\t0.0323459312223\n",
      "=========Test on depth = 5=========\n",
      "Training accuracy:\t\t\t0.854096520763\n",
      "10-fold cross-validation accuracy:\t0.825002837362\n",
      "Delta(training - validation): \t\t0.0290936834008\n",
      "=========Test on depth = 6=========\n",
      "Training accuracy:\t\t\t0.867564534231\n",
      "10-fold cross-validation accuracy:\t0.831756894791\n",
      "Delta(training - validation): \t\t0.0358076394406\n",
      "=========Test on depth = 7=========\n",
      "Training accuracy:\t\t\t0.882154882155\n",
      "10-fold cross-validation accuracy:\t0.828423845194\n",
      "Delta(training - validation): \t\t0.0537310369614\n",
      "=========Test on depth = 8=========\n",
      "Training accuracy:\t\t\t0.911335578002\n",
      "10-fold cross-validation accuracy:\t0.829547156963\n",
      "Delta(training - validation): \t\t0.0817884210394\n",
      "=========Test on depth = 9=========\n",
      "Training accuracy:\t\t\t0.920314253648\n",
      "10-fold cross-validation accuracy:\t0.828385540801\n",
      "Delta(training - validation): \t\t0.0919287128463\n",
      "=========Test on depth = 10=========\n",
      "Training accuracy:\t\t\t0.938271604938\n",
      "10-fold cross-validation accuracy:\t0.823928611962\n",
      "Delta(training - validation): \t\t0.114342992976\n",
      "=========Test on depth = 11=========\n",
      "Training accuracy:\t\t\t0.955106621773\n",
      "10-fold cross-validation accuracy:\t0.819446998071\n",
      "Delta(training - validation): \t\t0.135659623703\n",
      "=========Test on depth = 12=========\n",
      "Training accuracy:\t\t\t0.957351290685\n",
      "10-fold cross-validation accuracy:\t0.823966348882\n",
      "Delta(training - validation): \t\t0.133384941803\n",
      "=========Test on depth = 13=========\n",
      "Training accuracy:\t\t\t0.968574635241\n",
      "10-fold cross-validation accuracy:\t0.817237260243\n",
      "Delta(training - validation): \t\t0.151337374998\n",
      "=========Test on depth = 14=========\n",
      "Training accuracy:\t\t\t0.973063973064\n",
      "10-fold cross-validation accuracy:\t0.817199807059\n",
      "Delta(training - validation): \t\t0.155864166005\n",
      "=========Test on depth = 15=========\n",
      "Training accuracy:\t\t\t0.975308641975\n",
      "10-fold cross-validation accuracy:\t0.813854273068\n",
      "Delta(training - validation): \t\t0.161454368908\n",
      "=========Test on depth = 16=========\n",
      "Training accuracy:\t\t\t0.977553310887\n",
      "10-fold cross-validation accuracy:\t0.799234479628\n",
      "Delta(training - validation): \t\t0.178318831259\n",
      "=========Test on depth = 17=========\n",
      "Training accuracy:\t\t\t0.984287317621\n",
      "10-fold cross-validation accuracy:\t0.804865225287\n",
      "Delta(training - validation): \t\t0.179422092334\n",
      "=========Test on depth = 18=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.805976336398\n",
      "Delta(training - validation): \t\t0.180555650134\n",
      "=========Test on depth = 19=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.803741629781\n",
      "Delta(training - validation): \t\t0.182790356751\n",
      "=========Test on depth = 20=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.810495970945\n",
      "Delta(training - validation): \t\t0.176036015587\n",
      "=========Test on depth = 21=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.801531891953\n",
      "Delta(training - validation): \t\t0.185000094579\n",
      "=========Test on depth = 22=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.806014073317\n",
      "Delta(training - validation): \t\t0.180517913215\n",
      "=========Test on depth = 23=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.800383327659\n",
      "Delta(training - validation): \t\t0.186148658873\n",
      "=========Test on depth = 24=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.802643286801\n",
      "Delta(training - validation): \t\t0.183888699731\n"
     ]
    }
   ],
   "source": [
    "for depth in np.arange(1,25,1): \n",
    "    print '=========Test on depth = %s=========' % depth\n",
    "    test_model(RandomForestClassifier(n_estimators=300, max_depth=depth), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on depth = 5=========\n",
      "Training accuracy:\t\t\t0.841750841751\n",
      "10-fold cross-validation accuracy:\t0.811581545795\n",
      "Delta(training - validation): \t\t0.0301692959558\n",
      "=========Test on depth = 6=========\n",
      "Training accuracy:\t\t\t0.848484848485\n",
      "10-fold cross-validation accuracy:\t0.819396776756\n",
      "Delta(training - validation): \t\t0.0290880717285\n",
      "=========Test on depth = 7=========\n",
      "Training accuracy:\t\t\t0.859708193042\n",
      "10-fold cross-validation accuracy:\t0.820482635342\n",
      "Delta(training - validation): \t\t0.0392255576993\n",
      "=========Test on depth = 8=========\n",
      "Training accuracy:\t\t\t0.878787878788\n",
      "10-fold cross-validation accuracy:\t0.821656452162\n",
      "Delta(training - validation): \t\t0.0571314266258\n",
      "=========Test on depth = 9=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.823916411304\n",
      "Delta(training - validation): \t\t0.0694618154075\n",
      "=========Test on depth = 10=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.822805300193\n",
      "Delta(training - validation): \t\t0.082918605531\n",
      "=========Test on depth = 11=========\n",
      "Training accuracy:\t\t\t0.92480359147\n",
      "10-fold cross-validation accuracy:\t0.819434513676\n",
      "Delta(training - validation): \t\t0.105369077794\n",
      "=========Test on depth = 12=========\n",
      "Training accuracy:\t\t\t0.937149270483\n",
      "10-fold cross-validation accuracy:\t0.809359891045\n",
      "Delta(training - validation): \t\t0.127789379437\n",
      "=========Test on depth = 13=========\n",
      "Training accuracy:\t\t\t0.950617283951\n",
      "10-fold cross-validation accuracy:\t0.805963568267\n",
      "Delta(training - validation): \t\t0.144653715684\n",
      "=========Test on depth = 14=========\n",
      "Training accuracy:\t\t\t0.956228956229\n",
      "10-fold cross-validation accuracy:\t0.808248496198\n",
      "Delta(training - validation): \t\t0.147980460031\n",
      "=========Test on depth = 15=========\n",
      "Training accuracy:\t\t\t0.967452300786\n",
      "10-fold cross-validation accuracy:\t0.80376659857\n",
      "Delta(training - validation): \t\t0.163685702216\n",
      "=========Test on depth = 16=========\n",
      "Training accuracy:\t\t\t0.968574635241\n",
      "10-fold cross-validation accuracy:\t0.804865225287\n",
      "Delta(training - validation): \t\t0.163709409955\n"
     ]
    }
   ],
   "source": [
    "for depth in np.arange(5,17,1): \n",
    "    print '=========Test on depth = %s=========' % depth\n",
    "    test_model(ExtraTreesClassifier(n_estimators=300, max_depth=depth), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on depth = 5=========\n",
      "Training accuracy:\t\t\t0.859708193042\n",
      "10-fold cross-validation accuracy:\t0.821657019635\n",
      "Delta(training - validation): \t\t0.038051173407\n",
      "=========Test on depth = 6=========\n",
      "Training accuracy:\t\t\t0.86531986532\n",
      "10-fold cross-validation accuracy:\t0.826176370446\n",
      "Delta(training - validation): \t\t0.0391434948738\n",
      "=========Test on depth = 7=========\n",
      "Training accuracy:\t\t\t0.879910213244\n",
      "10-fold cross-validation accuracy:\t0.837400124844\n",
      "Delta(training - validation): \t\t0.0425100883996\n",
      "=========Test on depth = 8=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.827312450346\n",
      "Delta(training - validation): \t\t0.0750444520107\n",
      "=========Test on depth = 9=========\n",
      "Training accuracy:\t\t\t0.915824915825\n",
      "10-fold cross-validation accuracy:\t0.825039723073\n",
      "Delta(training - validation): \t\t0.0907851927515\n",
      "=========Test on depth = 10=========\n",
      "Training accuracy:\t\t\t0.93265993266\n",
      "10-fold cross-validation accuracy:\t0.829534105096\n",
      "Delta(training - validation): \t\t0.103125827564\n",
      "=========Test on depth = 11=========\n",
      "Training accuracy:\t\t\t0.948372615039\n",
      "10-fold cross-validation accuracy:\t0.821681704687\n",
      "Delta(training - validation): \t\t0.126690910352\n",
      "=========Test on depth = 12=========\n",
      "Training accuracy:\t\t\t0.95847362514\n",
      "10-fold cross-validation accuracy:\t0.820582794234\n",
      "Delta(training - validation): \t\t0.137890830906\n",
      "=========Test on depth = 13=========\n",
      "Training accuracy:\t\t\t0.964085297419\n",
      "10-fold cross-validation accuracy:\t0.817199807059\n",
      "Delta(training - validation): \t\t0.146885490359\n",
      "=========Test on depth = 14=========\n",
      "Training accuracy:\t\t\t0.971941638608\n",
      "10-fold cross-validation accuracy:\t0.811594313926\n",
      "Delta(training - validation): \t\t0.160347324683\n",
      "=========Test on depth = 15=========\n",
      "Training accuracy:\t\t\t0.97418630752\n",
      "10-fold cross-validation accuracy:\t0.808236011803\n",
      "Delta(training - validation): \t\t0.165950295716\n",
      "=========Test on depth = 16=========\n",
      "Training accuracy:\t\t\t0.975308641975\n",
      "10-fold cross-validation accuracy:\t0.809347122915\n",
      "Delta(training - validation): \t\t0.165961519061\n"
     ]
    }
   ],
   "source": [
    "for depth in np.arange(5,17,1): \n",
    "    print '=========Test on depth = %s=========' % depth\n",
    "    test_model(RandomForestClassifier(n_estimators=300, max_depth=depth, criterion='entropy'), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on n_estimators = 100=========\n",
      "Training accuracy:\t\t\t0.890011223345\n",
      "10-fold cross-validation accuracy:\t0.823853705595\n",
      "Delta(training - validation): \t\t0.0661575177493\n",
      "=========Test on n_estimators = 150=========\n",
      "Training accuracy:\t\t\t0.907968574635\n",
      "10-fold cross-validation accuracy:\t0.833979117013\n",
      "Delta(training - validation): \t\t0.0739894576224\n",
      "=========Test on n_estimators = 200=========\n",
      "Training accuracy:\t\t\t0.927048260382\n",
      "10-fold cross-validation accuracy:\t0.82948473499\n",
      "Delta(training - validation): \t\t0.0975635253912\n",
      "=========Test on n_estimators = 250=========\n",
      "Training accuracy:\t\t\t0.943883277217\n",
      "10-fold cross-validation accuracy:\t0.829497219385\n",
      "Delta(training - validation): \t\t0.114386057832\n",
      "=========Test on n_estimators = 300=========\n",
      "Training accuracy:\t\t\t0.951739618406\n",
      "10-fold cross-validation accuracy:\t0.827212291454\n",
      "Delta(training - validation): \t\t0.124527326952\n",
      "=========Test on n_estimators = 350=========\n",
      "Training accuracy:\t\t\t0.955106621773\n",
      "10-fold cross-validation accuracy:\t0.821594313926\n",
      "Delta(training - validation): \t\t0.133512307848\n",
      "=========Test on n_estimators = 400=========\n",
      "Training accuracy:\t\t\t0.95847362514\n",
      "10-fold cross-validation accuracy:\t0.820508171604\n",
      "Delta(training - validation): \t\t0.137965453537\n",
      "=========Test on n_estimators = 450=========\n",
      "Training accuracy:\t\t\t0.962962962963\n",
      "10-fold cross-validation accuracy:\t0.815988537056\n",
      "Delta(training - validation): \t\t0.146974425907\n",
      "=========Test on n_estimators = 500=========\n",
      "Training accuracy:\t\t\t0.964085297419\n",
      "10-fold cross-validation accuracy:\t0.814877425945\n",
      "Delta(training - validation): \t\t0.149207871474\n",
      "=========Test on n_estimators = 550=========\n",
      "Training accuracy:\t\t\t0.965207631874\n",
      "10-fold cross-validation accuracy:\t0.817124616956\n",
      "Delta(training - validation): \t\t0.148083014918\n",
      "=========Test on n_estimators = 600=========\n",
      "Training accuracy:\t\t\t0.965207631874\n",
      "10-fold cross-validation accuracy:\t0.813766314834\n",
      "Delta(training - validation): \t\t0.151441317041\n",
      "=========Test on n_estimators = 650=========\n",
      "Training accuracy:\t\t\t0.96632996633\n",
      "10-fold cross-validation accuracy:\t0.814889910339\n",
      "Delta(training - validation): \t\t0.151440055991\n"
     ]
    }
   ],
   "source": [
    "for n in np.arange(100,700,50): \n",
    "    print '=========Test on n_estimators = %s=========' % n\n",
    "    test_model(GradientBoostingClassifier(n_estimators=n), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "Xtrain = dtrain.drop(['Survived'], axis = 1)\n",
    "ytrain = dtrain['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_n</th>\n",
       "      <th>...</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_n</th>\n",
       "      <th>Title_Army</th>\n",
       "      <th>Title_Dr</th>\n",
       "      <th>Title_Master</th>\n",
       "      <th>Title_Miss</th>\n",
       "      <th>Title_Mr</th>\n",
       "      <th>Title_Mrs</th>\n",
       "      <th>Title_Rev</th>\n",
       "      <th>Title_Upper</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.584059</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.515736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282790</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.406983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.499636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.491419</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.826091</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.382078</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.090403</td>\n",
       "      <td>2.246209</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.207473</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>2.007806</td>\n",
       "      <td>-0.437586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.186597</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.056474</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.939769</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.325558</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.127360</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.127329</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.734694</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.499636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.696333</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>5.729626</td>\n",
       "      <td>-0.032240</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.186597</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.503577</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.901409</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.339645</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.090403</td>\n",
       "      <td>3.153038</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.075508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.400019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.299395</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.462710</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.516239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.138398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.319747</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.400019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.111280</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.500055</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132156</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.052787</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.638500</td>\n",
       "      <td>2.246209</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.237512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>5.729626</td>\n",
       "      <td>-0.029976</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.516239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.810011</td>\n",
       "      <td>2.246209</td>\n",
       "      <td>2.007806</td>\n",
       "      <td>4.631163</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.601083</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.503074</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.659376</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.430206</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.374188</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.139822</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.601083</td>\n",
       "      <td>6.780355</td>\n",
       "      <td>2.007806</td>\n",
       "      <td>0.738034</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.433425</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.400019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.922285</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.400019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.207473</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.382746</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.093796</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.354574</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.470456</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.939769</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.437586</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.282790</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.298871</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>0.395998</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244430</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.561017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.298871</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.480518</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.132156</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.178647</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.111280</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.516239</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.734694</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.463496</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.810011</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.196836</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.976726</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>1.011898</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.358108</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.138398</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.244430</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502740</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.584059</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.449995</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.132156</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.450331</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.358108</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.519761</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.696333</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>5.729626</td>\n",
       "      <td>-0.075508</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.207473</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.400019</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.810011</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.057899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.601083</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>2.007806</td>\n",
       "      <td>-0.189716</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.282790</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.057899</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.169113</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.505674</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
       "0           0    0 -0.584059  0.432550 -0.473408 -0.515736           0   \n",
       "1           1    1  0.621016  0.432550 -0.473408  0.772917           1   \n",
       "2           1    1 -0.282790 -0.474279 -0.473408 -0.502152           0   \n",
       "3           1    1  0.395064  0.432550 -0.473408  0.406983           0   \n",
       "4           0    0  0.395064 -0.474279 -0.473408 -0.499636           0   \n",
       "5           0    0  0.196836 -0.474279 -0.473408 -0.491419           0   \n",
       "6           0    0  1.826091 -0.474279 -0.473408  0.382078           0   \n",
       "7           0    0 -2.090403  2.246209  0.767199 -0.237512           0   \n",
       "8           1    1 -0.207473 -0.474279  2.007806 -0.437586           0   \n",
       "9           1    1 -1.186597  0.432550 -0.473408 -0.056474           1   \n",
       "10          1    1 -1.939769  0.432550  0.767199 -0.325558           0   \n",
       "11          1    1  2.127360 -0.474279 -0.473408 -0.127329           0   \n",
       "12          0    0 -0.734694 -0.474279 -0.473408 -0.499636           0   \n",
       "13          0    0  0.696333  0.432550  5.729626 -0.032240           0   \n",
       "14          0    1 -1.186597 -0.474279 -0.473408 -0.503577           0   \n",
       "15          1    1  1.901409 -0.474279 -0.473408 -0.339645           0   \n",
       "16          0    0 -2.090403  3.153038  0.767199 -0.075508           0   \n",
       "17          1    0  0.196836 -0.474279 -0.473408 -0.400019           0   \n",
       "18          0    1  0.093796  0.432550 -0.473408 -0.299395           0   \n",
       "19          1    1  0.462710 -0.474279 -0.473408 -0.516239           1   \n",
       "20          0    0  0.395064 -0.474279 -0.473408 -0.138398           0   \n",
       "21          1    0  0.319747 -0.474279 -0.473408 -0.400019           0   \n",
       "22          1    1 -1.111280 -0.474279 -0.473408 -0.500055           0   \n",
       "23          1    0 -0.132156 -0.474279 -0.473408  0.052787           0   \n",
       "24          0    1 -1.638500  2.246209  0.767199 -0.237512           0   \n",
       "25          1    1  0.621016  0.432550  5.729626 -0.029976           0   \n",
       "26          0    0  0.196836 -0.474279 -0.473408 -0.516239           1   \n",
       "27          0    0 -0.810011  2.246209  2.007806  4.631163           0   \n",
       "28          1    1 -0.601083 -0.474279 -0.473408 -0.503074           0   \n",
       "29          0    0  0.196836 -0.474279 -0.473408 -0.502740           0   \n",
       "..        ...  ...       ...       ...       ...       ...         ...   \n",
       "861         0    0 -0.659376  0.432550 -0.473408 -0.430206           0   \n",
       "862         1    1  1.374188 -0.474279 -0.473408 -0.139822           0   \n",
       "863         0    1 -0.601083  6.780355  2.007806  0.738034           0   \n",
       "864         0    0 -0.433425 -0.474279 -0.473408 -0.400019           0   \n",
       "865         1    1  0.922285 -0.474279 -0.473408 -0.400019           0   \n",
       "866         1    1 -0.207473  0.432550 -0.473408 -0.382746           1   \n",
       "867         0    0  0.093796 -0.474279 -0.473408  0.354574           0   \n",
       "868         0    0  0.196836 -0.474279 -0.473408 -0.470456           0   \n",
       "869         1    0 -1.939769  0.432550  0.767199 -0.437586           0   \n",
       "870         0    0 -0.282790 -0.474279 -0.473408 -0.502740           0   \n",
       "871         1    1  1.298871  0.432550  0.767199  0.395998           0   \n",
       "872         0    0  0.244430 -0.474279 -0.473408 -0.561017           0   \n",
       "873         0    0  1.298871 -0.474279 -0.473408 -0.480518           0   \n",
       "874         1    1 -0.132156  0.432550 -0.473408 -0.178647           1   \n",
       "875         1    1 -1.111280 -0.474279 -0.473408 -0.516239           1   \n",
       "876         0    0 -0.734694 -0.474279 -0.473408 -0.463496           0   \n",
       "877         0    0 -0.810011 -0.474279 -0.473408 -0.502740           0   \n",
       "878         0    0  0.196836 -0.474279 -0.473408 -0.502740           0   \n",
       "879         1    1  1.976726 -0.474279  0.767199  1.011898           1   \n",
       "880         1    1 -0.358108 -0.474279  0.767199 -0.138398           0   \n",
       "881         0    0  0.244430 -0.474279 -0.473408 -0.502740           0   \n",
       "882         0    1 -0.584059 -0.474279 -0.473408 -0.449995           0   \n",
       "883         0    0 -0.132156 -0.474279 -0.473408 -0.450331           0   \n",
       "884         0    0 -0.358108 -0.474279 -0.473408 -0.519761           0   \n",
       "885         0    1  0.696333 -0.474279  5.729626 -0.075508           0   \n",
       "886         0    0 -0.207473 -0.474279 -0.473408 -0.400019           0   \n",
       "887         1    1 -0.810011 -0.474279 -0.473408 -0.057899           0   \n",
       "888         0    1 -0.601083  0.432550  2.007806 -0.189716           0   \n",
       "889         1    0 -0.282790 -0.474279 -0.473408 -0.057899           1   \n",
       "890         0    0  0.169113 -0.474279 -0.473408 -0.505674           0   \n",
       "\n",
       "     Embarked_Q  Embarked_S  Embarked_n     ...       Cabin_G  Cabin_n  \\\n",
       "0             0           1           0     ...             0        1   \n",
       "1             0           0           0     ...             0        0   \n",
       "2             0           1           0     ...             0        1   \n",
       "3             0           1           0     ...             0        0   \n",
       "4             0           1           0     ...             0        1   \n",
       "5             1           0           0     ...             0        1   \n",
       "6             0           1           0     ...             0        0   \n",
       "7             0           1           0     ...             0        1   \n",
       "8             0           1           0     ...             0        1   \n",
       "9             0           0           0     ...             0        1   \n",
       "10            0           1           0     ...             1        0   \n",
       "11            0           1           0     ...             0        0   \n",
       "12            0           1           0     ...             0        1   \n",
       "13            0           1           0     ...             0        1   \n",
       "14            0           1           0     ...             0        1   \n",
       "15            0           1           0     ...             0        1   \n",
       "16            1           0           0     ...             0        1   \n",
       "17            0           1           0     ...             0        1   \n",
       "18            0           1           0     ...             0        1   \n",
       "19            0           0           0     ...             0        1   \n",
       "20            0           1           0     ...             0        1   \n",
       "21            0           1           0     ...             0        0   \n",
       "22            1           0           0     ...             0        1   \n",
       "23            0           1           0     ...             0        0   \n",
       "24            0           1           0     ...             0        1   \n",
       "25            0           1           0     ...             0        1   \n",
       "26            0           0           0     ...             0        1   \n",
       "27            0           1           0     ...             0        0   \n",
       "28            1           0           0     ...             0        1   \n",
       "29            0           1           0     ...             0        1   \n",
       "..          ...         ...         ...     ...           ...      ...   \n",
       "861           0           1           0     ...             0        1   \n",
       "862           0           1           0     ...             0        0   \n",
       "863           0           1           0     ...             0        1   \n",
       "864           0           1           0     ...             0        1   \n",
       "865           0           1           0     ...             0        1   \n",
       "866           0           0           0     ...             0        1   \n",
       "867           0           1           0     ...             0        0   \n",
       "868           0           1           0     ...             0        1   \n",
       "869           0           1           0     ...             0        1   \n",
       "870           0           1           0     ...             0        1   \n",
       "871           0           1           0     ...             0        0   \n",
       "872           0           1           0     ...             0        0   \n",
       "873           0           1           0     ...             0        1   \n",
       "874           0           0           0     ...             0        1   \n",
       "875           0           0           0     ...             0        1   \n",
       "876           0           1           0     ...             0        1   \n",
       "877           0           1           0     ...             0        1   \n",
       "878           0           1           0     ...             0        1   \n",
       "879           0           0           0     ...             0        0   \n",
       "880           0           1           0     ...             0        1   \n",
       "881           0           1           0     ...             0        1   \n",
       "882           0           1           0     ...             0        1   \n",
       "883           0           1           0     ...             0        1   \n",
       "884           0           1           0     ...             0        1   \n",
       "885           1           0           0     ...             0        1   \n",
       "886           0           1           0     ...             0        1   \n",
       "887           0           1           0     ...             0        0   \n",
       "888           0           1           0     ...             0        1   \n",
       "889           0           0           0     ...             0        0   \n",
       "890           1           0           0     ...             0        1   \n",
       "\n",
       "     Title_Army  Title_Dr  Title_Master  Title_Miss  Title_Mr  Title_Mrs  \\\n",
       "0             0         0             0           0         1          0   \n",
       "1             0         0             0           0         0          1   \n",
       "2             0         0             0           1         0          0   \n",
       "3             0         0             0           0         0          1   \n",
       "4             0         0             0           0         1          0   \n",
       "5             0         0             0           0         1          0   \n",
       "6             0         0             0           0         1          0   \n",
       "7             0         0             1           0         0          0   \n",
       "8             0         0             0           0         0          1   \n",
       "9             0         0             0           0         0          1   \n",
       "10            0         0             0           1         0          0   \n",
       "11            0         0             0           1         0          0   \n",
       "12            0         0             0           0         1          0   \n",
       "13            0         0             0           0         1          0   \n",
       "14            0         0             0           1         0          0   \n",
       "15            0         0             0           0         0          1   \n",
       "16            0         0             1           0         0          0   \n",
       "17            0         0             0           0         1          0   \n",
       "18            0         0             0           0         0          1   \n",
       "19            0         0             0           0         0          1   \n",
       "20            0         0             0           0         1          0   \n",
       "21            0         0             0           0         1          0   \n",
       "22            0         0             0           1         0          0   \n",
       "23            0         0             0           0         1          0   \n",
       "24            0         0             0           1         0          0   \n",
       "25            0         0             0           0         0          1   \n",
       "26            0         0             0           0         1          0   \n",
       "27            0         0             0           0         1          0   \n",
       "28            0         0             0           1         0          0   \n",
       "29            0         0             0           0         1          0   \n",
       "..          ...       ...           ...         ...       ...        ...   \n",
       "861           0         0             0           0         1          0   \n",
       "862           0         0             0           0         0          1   \n",
       "863           0         0             0           1         0          0   \n",
       "864           0         0             0           0         1          0   \n",
       "865           0         0             0           0         0          1   \n",
       "866           0         0             0           1         0          0   \n",
       "867           0         0             0           0         1          0   \n",
       "868           0         0             0           0         1          0   \n",
       "869           0         0             1           0         0          0   \n",
       "870           0         0             0           0         1          0   \n",
       "871           0         0             0           0         0          1   \n",
       "872           0         0             0           0         1          0   \n",
       "873           0         0             0           0         1          0   \n",
       "874           0         0             0           0         0          1   \n",
       "875           0         0             0           1         0          0   \n",
       "876           0         0             0           0         1          0   \n",
       "877           0         0             0           0         1          0   \n",
       "878           0         0             0           0         1          0   \n",
       "879           0         0             0           0         0          1   \n",
       "880           0         0             0           0         0          1   \n",
       "881           0         0             0           0         1          0   \n",
       "882           0         0             0           1         0          0   \n",
       "883           0         0             0           0         1          0   \n",
       "884           0         0             0           0         1          0   \n",
       "885           0         0             0           0         0          1   \n",
       "886           0         0             0           0         0          0   \n",
       "887           0         0             0           1         0          0   \n",
       "888           0         0             0           1         0          0   \n",
       "889           0         0             0           0         1          0   \n",
       "890           0         0             0           0         1          0   \n",
       "\n",
       "     Title_Rev  Title_Upper  \n",
       "0            0            0  \n",
       "1            0            0  \n",
       "2            0            0  \n",
       "3            0            0  \n",
       "4            0            0  \n",
       "5            0            0  \n",
       "6            0            0  \n",
       "7            0            0  \n",
       "8            0            0  \n",
       "9            0            0  \n",
       "10           0            0  \n",
       "11           0            0  \n",
       "12           0            0  \n",
       "13           0            0  \n",
       "14           0            0  \n",
       "15           0            0  \n",
       "16           0            0  \n",
       "17           0            0  \n",
       "18           0            0  \n",
       "19           0            0  \n",
       "20           0            0  \n",
       "21           0            0  \n",
       "22           0            0  \n",
       "23           0            0  \n",
       "24           0            0  \n",
       "25           0            0  \n",
       "26           0            0  \n",
       "27           0            0  \n",
       "28           0            0  \n",
       "29           0            0  \n",
       "..         ...          ...  \n",
       "861          0            0  \n",
       "862          0            0  \n",
       "863          0            0  \n",
       "864          0            0  \n",
       "865          0            0  \n",
       "866          0            0  \n",
       "867          0            0  \n",
       "868          0            0  \n",
       "869          0            0  \n",
       "870          0            0  \n",
       "871          0            0  \n",
       "872          0            0  \n",
       "873          0            0  \n",
       "874          0            0  \n",
       "875          0            0  \n",
       "876          0            0  \n",
       "877          0            0  \n",
       "878          0            0  \n",
       "879          0            0  \n",
       "880          0            0  \n",
       "881          0            0  \n",
       "882          0            0  \n",
       "883          0            0  \n",
       "884          0            0  \n",
       "885          0            0  \n",
       "886          1            0  \n",
       "887          0            0  \n",
       "888          0            0  \n",
       "889          0            0  \n",
       "890          0            0  \n",
       "\n",
       "[891 rows x 29 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5)\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on c = 0.0001=========\n",
      "Training accuracy:\t\t\t0.616161616162\n",
      "10-fold cross-validation accuracy:\t0.616170128249\n",
      "Delta(training - validation): \t\t-8.51208716379e-06\n",
      "=========Test on c = 0.001=========\n",
      "Training accuracy:\t\t\t0.616161616162\n",
      "10-fold cross-validation accuracy:\t0.616170128249\n",
      "Delta(training - validation): \t\t-8.51208716379e-06\n",
      "=========Test on c = 0.01=========\n",
      "Training accuracy:\t\t\t0.616161616162\n",
      "10-fold cross-validation accuracy:\t0.616170128249\n",
      "Delta(training - validation): \t\t-8.51208716379e-06\n",
      "=========Test on c = 0.1=========\n",
      "Training accuracy:\t\t\t0.821548821549\n",
      "10-fold cross-validation accuracy:\t0.815976052661\n",
      "Delta(training - validation): \t\t0.00557276888738\n",
      "=========Test on c = 1=========\n",
      "Training accuracy:\t\t\t0.837261503928\n",
      "10-fold cross-validation accuracy:\t0.833878674384\n",
      "Delta(training - validation): \t\t0.00338282954388\n",
      "=========Test on c = 3=========\n",
      "Training accuracy:\t\t\t0.840628507295\n",
      "10-fold cross-validation accuracy:\t0.835015038021\n",
      "Delta(training - validation): \t\t0.00561346927452\n",
      "=========Test on c = 10=========\n",
      "Training accuracy:\t\t\t0.855218855219\n",
      "10-fold cross-validation accuracy:\t0.839547156963\n",
      "Delta(training - validation): \t\t0.015671698256\n",
      "=========Test on c = 30=========\n",
      "Training accuracy:\t\t\t0.870931537598\n",
      "10-fold cross-validation accuracy:\t0.822768130746\n",
      "Delta(training - validation): \t\t0.0481634068525\n",
      "=========Test on c = 100=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.821695040291\n",
      "Delta(training - validation): \t\t0.0638268452313\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.816064010895\n",
      "Delta(training - validation): \t\t0.0773142158161\n"
     ]
    }
   ],
   "source": [
    "for c in [0.0001,0.001,0.01,0.1,1,3,10,30,100, 300]: \n",
    "    print '=========Test on c = %s=========' % c\n",
    "    test_model(SVC(C=c), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t\t\t0.837261503928\n",
      "10-fold cross-validation accuracy:\t0.833878674384\n",
      "Delta(training - validation): \t\t0.00338282954388\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(SVC(), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t\t\t0.821548821549\n",
      "10-fold cross-validation accuracy:\t0.815976052661\n",
      "Delta(training - validation): \t\t0.00557276888738\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=0.1, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(SVC(kernel='rbf', C=0.1), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on c = 0.0001=========\n",
      "Training accuracy:\t\t\t0.616161616162\n",
      "10-fold cross-validation accuracy:\t0.616170128249\n",
      "Delta(training - validation): \t\t-8.51208716379e-06\n",
      "=========Test on c = 0.001=========\n",
      "Training accuracy:\t\t\t0.631874298541\n",
      "10-fold cross-validation accuracy:\t0.620652025877\n",
      "Delta(training - validation): \t\t0.0112222726642\n",
      "=========Test on c = 0.01=========\n",
      "Training accuracy:\t\t\t0.805836139169\n",
      "10-fold cross-validation accuracy:\t0.804701793213\n",
      "Delta(training - validation): \t\t0.00113434595644\n",
      "=========Test on c = 0.1=========\n",
      "Training accuracy:\t\t\t0.83164983165\n",
      "10-fold cross-validation accuracy:\t0.822667404381\n",
      "Delta(training - validation): \t\t0.00898242726894\n",
      "=========Test on c = 1=========\n",
      "Training accuracy:\t\t\t0.838383838384\n",
      "10-fold cross-validation accuracy:\t0.820445182159\n",
      "Delta(training - validation): \t\t0.0179386562252\n",
      "=========Test on c = 3=========\n",
      "Training accuracy:\t\t\t0.836139169473\n",
      "10-fold cross-validation accuracy:\t0.821581545795\n",
      "Delta(training - validation): \t\t0.0145576236775\n",
      "=========Test on c = 10=========\n",
      "Training accuracy:\t\t\t"
     ]
    }
   ],
   "source": [
    "for c in [0.0001,0.001,0.01,0.1,1,3,10,30]: \n",
    "    print '=========Test on c = %s=========' % c\n",
    "    test_model(SVC(C=c, kernel='linear'), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.717171717172\n",
      "10-fold cross-validation accuracy:\t0.701553172171\n",
      "Delta(training - validation): \t\t0.0156185450006\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.812570145903\n",
      "10-fold cross-validation accuracy:\t0.802442117807\n",
      "Delta(training - validation): \t\t0.0101280280962\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.835016835017\n",
      "10-fold cross-validation accuracy:\t0.835015038021\n",
      "Delta(training - validation): \t\t1.79699617897e-06\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.821682555896\n",
      "Delta(training - validation): \t\t0.0615946607145\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.914702581369\n",
      "10-fold cross-validation accuracy:\t0.796948984224\n",
      "Delta(training - validation): \t\t0.117753597145\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.925925925926\n",
      "10-fold cross-validation accuracy:\t0.74873340143\n",
      "Delta(training - validation): \t\t0.177192524496\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.945005611672\n",
      "10-fold cross-validation accuracy:\t0.727472193849\n",
      "Delta(training - validation): \t\t0.217533417824\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.95847362514\n",
      "10-fold cross-validation accuracy:\t0.658854556804\n",
      "Delta(training - validation): \t\t0.299619068336\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.96632996633\n",
      "10-fold cross-validation accuracy:\t0.655333390081\n",
      "Delta(training - validation): \t\t0.310996576249\n",
      "=========Test on c = 300=========\n",
      "Training accuracy:\t\t\t0.971941638608\n",
      "10-fold cross-validation accuracy:\t0.645183009874\n",
      "Delta(training - validation): \t\t0.326758628734\n"
     ]
    }
   ],
   "source": [
    "for gamma in [0.0001,0.001,0.01,0.1,1,3,10,30,100, 300]: \n",
    "    print '=========Test on c = %s=========' % c\n",
    "    test_model(SVC(gamma=gamma, C = 10), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on gamma = 0.001=========\n",
      "Training accuracy:\t\t\t0.812570145903\n",
      "10-fold cross-validation accuracy:\t0.802442117807\n",
      "Delta(training - validation): \t\t0.0101280280962\n",
      "=========Test on gamma = 0.003=========\n",
      "Training accuracy:\t\t\t0.833894500561\n",
      "10-fold cross-validation accuracy:\t0.826025990239\n",
      "Delta(training - validation): \t\t0.00786851032169\n",
      "=========Test on gamma = 0.005=========\n",
      "Training accuracy:\t\t\t0.835016835017\n",
      "10-fold cross-validation accuracy:\t0.830507887867\n",
      "Delta(training - validation): \t\t0.0045089471494\n",
      "=========Test on gamma = 0.007=========\n",
      "Training accuracy:\t\t\t0.835016835017\n",
      "10-fold cross-validation accuracy:\t0.832755078879\n",
      "Delta(training - validation): \t\t0.00226175613816\n",
      "=========Test on gamma = 0.009=========\n",
      "Training accuracy:\t\t\t0.835016835017\n",
      "10-fold cross-validation accuracy:\t0.835015038021\n",
      "Delta(training - validation): \t\t1.79699617897e-06\n",
      "=========Test on gamma = 0.011=========\n",
      "Training accuracy:\t\t\t0.836139169473\n",
      "10-fold cross-validation accuracy:\t0.836126149132\n",
      "Delta(training - validation): \t\t1.30203407356e-05\n",
      "=========Test on gamma = 0.013=========\n",
      "Training accuracy:\t\t\t0.837261503928\n",
      "10-fold cross-validation accuracy:\t0.833891442515\n",
      "Delta(training - validation): \t\t0.00337006141313\n",
      "=========Test on gamma = 0.015=========\n",
      "Training accuracy:\t\t\t0.837261503928\n",
      "10-fold cross-validation accuracy:\t0.83390392691\n",
      "Delta(training - validation): \t\t0.00335757701863\n",
      "=========Test on gamma = 0.017=========\n",
      "Training accuracy:\t\t\t0.83950617284\n",
      "10-fold cross-validation accuracy:\t0.832792815798\n",
      "Delta(training - validation): \t\t0.00671335704107\n",
      "=========Test on gamma = 0.019=========\n",
      "Training accuracy:\t\t\t0.83950617284\n",
      "10-fold cross-validation accuracy:\t0.835040290546\n",
      "Delta(training - validation): \t\t0.0044658822936\n",
      "=========Test on gamma = 0.021=========\n",
      "Training accuracy:\t\t\t0.840628507295\n",
      "10-fold cross-validation accuracy:\t0.835040290546\n",
      "Delta(training - validation): \t\t0.00558821674927\n",
      "=========Test on gamma = 0.023=========\n",
      "Training accuracy:\t\t\t0.841750841751\n",
      "10-fold cross-validation accuracy:\t0.831681988424\n",
      "Delta(training - validation): \t\t0.0100688533273\n",
      "=========Test on gamma = 0.025=========\n",
      "Training accuracy:\t\t\t0.842873176207\n",
      "10-fold cross-validation accuracy:\t0.831681988424\n",
      "Delta(training - validation): \t\t0.0111911877829\n",
      "=========Test on gamma = 0.027=========\n",
      "Training accuracy:\t\t\t0.846240179574\n",
      "10-fold cross-validation accuracy:\t0.831694472818\n",
      "Delta(training - validation): \t\t0.0145457067554\n",
      "=========Test on gamma = 0.029=========\n",
      "Training accuracy:\t\t\t0.850729517396\n",
      "10-fold cross-validation accuracy:\t0.83505277494\n",
      "Delta(training - validation): \t\t0.0156767424558\n",
      "=========Test on gamma = 0.031=========\n",
      "Training accuracy:\t\t\t0.851851851852\n",
      "10-fold cross-validation accuracy:\t0.832830552718\n",
      "Delta(training - validation): \t\t0.0190212991337\n",
      "=========Test on gamma = 0.033=========\n",
      "Training accuracy:\t\t\t0.852974186308\n",
      "10-fold cross-validation accuracy:\t0.836201339235\n",
      "Delta(training - validation): \t\t0.0167728470725\n",
      "=========Test on gamma = 0.035=========\n",
      "Training accuracy:\t\t\t0.855218855219\n",
      "10-fold cross-validation accuracy:\t0.838436045852\n",
      "Delta(training - validation): \t\t0.0167828093671\n",
      "=========Test on gamma = 0.037=========\n",
      "Training accuracy:\t\t\t0.854096520763\n",
      "10-fold cross-validation accuracy:\t0.836201339235\n",
      "Delta(training - validation): \t\t0.0178951815281\n",
      "=========Test on gamma = 0.039=========\n",
      "Training accuracy:\t\t\t0.855218855219\n",
      "10-fold cross-validation accuracy:\t0.836201339235\n",
      "Delta(training - validation): \t\t0.0190175159838\n",
      "=========Test on gamma = 0.041=========\n",
      "Training accuracy:\t\t\t0.859708193042\n",
      "10-fold cross-validation accuracy:\t0.832843037113\n",
      "Delta(training - validation): \t\t0.0268651559288\n",
      "=========Test on gamma = 0.043=========\n",
      "Training accuracy:\t\t\t0.855218855219\n",
      "10-fold cross-validation accuracy:\t0.833966632618\n",
      "Delta(training - validation): \t\t0.0212522226005\n",
      "=========Test on gamma = 0.045=========\n",
      "Training accuracy:\t\t\t0.858585858586\n",
      "10-fold cross-validation accuracy:\t0.829459482465\n",
      "Delta(training - validation): \t\t0.0291263761208\n",
      "=========Test on gamma = 0.047=========\n",
      "Training accuracy:\t\t\t0.858585858586\n",
      "10-fold cross-validation accuracy:\t0.829459198729\n",
      "Delta(training - validation): \t\t0.029126659857\n",
      "=========Test on gamma = 0.049=========\n",
      "Training accuracy:\t\t\t0.860830527497\n",
      "10-fold cross-validation accuracy:\t0.826100896607\n",
      "Delta(training - validation): \t\t0.0347296308907\n",
      "=========Test on gamma = 0.051=========\n",
      "Training accuracy:\t\t\t0.861952861953\n",
      "10-fold cross-validation accuracy:\t0.829459198729\n",
      "Delta(training - validation): \t\t0.032493663224\n",
      "=========Test on gamma = 0.053=========\n",
      "Training accuracy:\t\t\t0.861952861953\n",
      "10-fold cross-validation accuracy:\t0.827249460901\n",
      "Delta(training - validation): \t\t0.0347034010517\n",
      "=========Test on gamma = 0.055=========\n",
      "Training accuracy:\t\t\t0.864197530864\n",
      "10-fold cross-validation accuracy:\t0.825014754284\n",
      "Delta(training - validation): \t\t0.0391827765798\n",
      "=========Test on gamma = 0.057=========\n",
      "Training accuracy:\t\t\t0.86531986532\n",
      "10-fold cross-validation accuracy:\t0.825027522415\n",
      "Delta(training - validation): \t\t0.0402923429047\n",
      "=========Test on gamma = 0.059=========\n",
      "Training accuracy:\t\t\t0.867564534231\n",
      "10-fold cross-validation accuracy:\t0.823891442515\n",
      "Delta(training - validation): \t\t0.0436730917162\n",
      "=========Test on gamma = 0.061=========\n",
      "Training accuracy:\t\t\t0.869809203143\n",
      "10-fold cross-validation accuracy:\t0.823904210646\n",
      "Delta(training - validation): \t\t0.0459049924968\n",
      "=========Test on gamma = 0.063=========\n",
      "Training accuracy:\t\t\t0.869809203143\n",
      "10-fold cross-validation accuracy:\t0.820545908523\n",
      "Delta(training - validation): \t\t0.0492632946191\n",
      "=========Test on gamma = 0.065=========\n",
      "Training accuracy:\t\t\t0.870931537598\n",
      "10-fold cross-validation accuracy:\t0.82278061514\n",
      "Delta(training - validation): \t\t0.048150922458\n",
      "=========Test on gamma = 0.067=========\n",
      "Training accuracy:\t\t\t0.870931537598\n",
      "10-fold cross-validation accuracy:\t0.823916978777\n",
      "Delta(training - validation): \t\t0.0470145588217\n",
      "=========Test on gamma = 0.069=========\n",
      "Training accuracy:\t\t\t0.870931537598\n",
      "10-fold cross-validation accuracy:\t0.826176937919\n",
      "Delta(training - validation): \t\t0.0447545996797\n",
      "=========Test on gamma = 0.071=========\n",
      "Training accuracy:\t\t\t0.870931537598\n",
      "10-fold cross-validation accuracy:\t0.827300533424\n",
      "Delta(training - validation): \t\t0.0436310041741\n",
      "=========Test on gamma = 0.073=========\n",
      "Training accuracy:\t\t\t0.874298540965\n",
      "10-fold cross-validation accuracy:\t0.828411644535\n",
      "Delta(training - validation): \t\t0.04588689643\n",
      "=========Test on gamma = 0.075=========\n",
      "Training accuracy:\t\t\t0.875420875421\n",
      "10-fold cross-validation accuracy:\t0.828411644535\n",
      "Delta(training - validation): \t\t0.0470092308856\n",
      "=========Test on gamma = 0.077=========\n",
      "Training accuracy:\t\t\t0.875420875421\n",
      "10-fold cross-validation accuracy:\t0.827275564635\n",
      "Delta(training - validation): \t\t0.0481453107858\n",
      "=========Test on gamma = 0.079=========\n",
      "Training accuracy:\t\t\t0.876543209877\n",
      "10-fold cross-validation accuracy:\t0.828399160141\n",
      "Delta(training - validation): \t\t0.0481440497358\n",
      "=========Test on gamma = 0.081=========\n",
      "Training accuracy:\t\t\t0.877665544332\n",
      "10-fold cross-validation accuracy:\t0.829510271252\n",
      "Delta(training - validation): \t\t0.0481552730804\n",
      "=========Test on gamma = 0.083=========\n",
      "Training accuracy:\t\t\t0.877665544332\n",
      "10-fold cross-validation accuracy:\t0.829510271252\n",
      "Delta(training - validation): \t\t0.0481552730804\n",
      "=========Test on gamma = 0.085=========\n",
      "Training accuracy:\t\t\t0.877665544332\n",
      "10-fold cross-validation accuracy:\t0.827275564635\n",
      "Delta(training - validation): \t\t0.0503899796971\n",
      "=========Test on gamma = 0.087=========\n",
      "Training accuracy:\t\t\t0.877665544332\n",
      "10-fold cross-validation accuracy:\t0.826151969129\n",
      "Delta(training - validation): \t\t0.0515135752027\n",
      "=========Test on gamma = 0.089=========\n",
      "Training accuracy:\t\t\t0.878787878788\n",
      "10-fold cross-validation accuracy:\t0.826151969129\n",
      "Delta(training - validation): \t\t0.0526359096584\n",
      "=========Test on gamma = 0.091=========\n",
      "Training accuracy:\t\t\t0.879910213244\n",
      "10-fold cross-validation accuracy:\t0.826151969129\n",
      "Delta(training - validation): \t\t0.053758244114\n",
      "=========Test on gamma = 0.093=========\n",
      "Training accuracy:\t\t\t0.882154882155\n",
      "10-fold cross-validation accuracy:\t0.825028373624\n",
      "Delta(training - validation): \t\t0.057126508531\n",
      "=========Test on gamma = 0.095=========\n",
      "Training accuracy:\t\t\t0.882154882155\n",
      "10-fold cross-validation accuracy:\t0.825028373624\n",
      "Delta(training - validation): \t\t0.057126508531\n",
      "=========Test on gamma = 0.097=========\n",
      "Training accuracy:\t\t\t0.882154882155\n",
      "10-fold cross-validation accuracy:\t0.822793667007\n",
      "Delta(training - validation): \t\t0.0593612151477\n",
      "=========Test on gamma = 0.099=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.821682555896\n",
      "Delta(training - validation): \t\t0.0615946607145\n",
      "=========Test on gamma = 0.101=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.820571444785\n",
      "Delta(training - validation): \t\t0.0627057718256\n",
      "=========Test on gamma = 0.103=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.820571444785\n",
      "Delta(training - validation): \t\t0.0627057718256\n",
      "=========Test on gamma = 0.105=========\n",
      "Training accuracy:\t\t\t0.884399551066\n",
      "10-fold cross-validation accuracy:\t0.820571444785\n",
      "Delta(training - validation): \t\t0.0638281062813\n",
      "=========Test on gamma = 0.107=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.819473101805\n",
      "Delta(training - validation): \t\t0.0660487837173\n",
      "=========Test on gamma = 0.109=========\n",
      "Training accuracy:\t\t\t0.886644219978\n",
      "10-fold cross-validation accuracy:\t0.819473101805\n",
      "Delta(training - validation): \t\t0.067171118173\n",
      "=========Test on gamma = 0.111=========\n",
      "Training accuracy:\t\t\t0.886644219978\n",
      "10-fold cross-validation accuracy:\t0.819473101805\n",
      "Delta(training - validation): \t\t0.067171118173\n",
      "=========Test on gamma = 0.113=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.819473101805\n",
      "Delta(training - validation): \t\t0.0660487837173\n",
      "=========Test on gamma = 0.115=========\n",
      "Training accuracy:\t\t\t0.884399551066\n",
      "10-fold cross-validation accuracy:\t0.819473101805\n",
      "Delta(training - validation): \t\t0.0649264492617\n",
      "=========Test on gamma = 0.117=========\n",
      "Training accuracy:\t\t\t0.884399551066\n",
      "10-fold cross-validation accuracy:\t0.821707808421\n",
      "Delta(training - validation): \t\t0.0626917426449\n",
      "=========Test on gamma = 0.119=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.821707808421\n",
      "Delta(training - validation): \t\t0.0615694081893\n",
      "=========Test on gamma = 0.121=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.820584212916\n",
      "Delta(training - validation): \t\t0.0626930036949\n",
      "=========Test on gamma = 0.123=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.820584212916\n",
      "Delta(training - validation): \t\t0.0626930036949\n",
      "=========Test on gamma = 0.125=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.821695324027\n",
      "Delta(training - validation): \t\t0.0615818925838\n",
      "=========Test on gamma = 0.127=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.822818919532\n",
      "Delta(training - validation): \t\t0.0627029659895\n",
      "=========Test on gamma = 0.129=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.821682555896\n",
      "Delta(training - validation): \t\t0.0638393296258\n",
      "=========Test on gamma = 0.131=========\n",
      "Training accuracy:\t\t\t0.883277216611\n",
      "10-fold cross-validation accuracy:\t0.821682555896\n",
      "Delta(training - validation): \t\t0.0615946607145\n",
      "=========Test on gamma = 0.133=========\n",
      "Training accuracy:\t\t\t0.884399551066\n",
      "10-fold cross-validation accuracy:\t0.821682555896\n",
      "Delta(training - validation): \t\t0.0627169951702\n",
      "=========Test on gamma = 0.135=========\n",
      "Training accuracy:\t\t\t0.887766554433\n",
      "10-fold cross-validation accuracy:\t0.82055896039\n",
      "Delta(training - validation): \t\t0.0672075940428\n",
      "=========Test on gamma = 0.137=========\n",
      "Training accuracy:\t\t\t0.887766554433\n",
      "10-fold cross-validation accuracy:\t0.82055896039\n",
      "Delta(training - validation): \t\t0.0672075940428\n",
      "=========Test on gamma = 0.139=========\n",
      "Training accuracy:\t\t\t0.887766554433\n",
      "10-fold cross-validation accuracy:\t0.819447849279\n",
      "Delta(training - validation): \t\t0.0683187051539\n",
      "=========Test on gamma = 0.141=========\n",
      "Training accuracy:\t\t\t0.886644219978\n",
      "10-fold cross-validation accuracy:\t0.816077062762\n",
      "Delta(training - validation): \t\t0.0705671572151\n",
      "=========Test on gamma = 0.143=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.814953467257\n",
      "Delta(training - validation): \t\t0.070568418265\n",
      "=========Test on gamma = 0.145=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.816077062762\n",
      "Delta(training - validation): \t\t0.0694448227594\n",
      "=========Test on gamma = 0.147=========\n",
      "Training accuracy:\t\t\t0.886644219978\n",
      "10-fold cross-validation accuracy:\t0.816077062762\n",
      "Delta(training - validation): \t\t0.0705671572151\n",
      "=========Test on gamma = 0.149=========\n",
      "Training accuracy:\t\t\t0.886644219978\n",
      "10-fold cross-validation accuracy:\t0.817200658268\n",
      "Delta(training - validation): \t\t0.0694435617095\n",
      "=========Test on gamma = 0.151=========\n",
      "Training accuracy:\t\t\t0.886644219978\n",
      "10-fold cross-validation accuracy:\t0.817200658268\n",
      "Delta(training - validation): \t\t0.0694435617095\n",
      "=========Test on gamma = 0.153=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.813829588015\n",
      "Delta(training - validation): \t\t0.0750593008739\n",
      "=========Test on gamma = 0.155=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.813829588015\n",
      "Delta(training - validation): \t\t0.0750593008739\n",
      "=========Test on gamma = 0.157=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.813829588015\n",
      "Delta(training - validation): \t\t0.0750593008739\n",
      "=========Test on gamma = 0.159=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.813829588015\n",
      "Delta(training - validation): \t\t0.0750593008739\n",
      "=========Test on gamma = 0.161=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.814953183521\n",
      "Delta(training - validation): \t\t0.0739357053683\n",
      "=========Test on gamma = 0.163=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.816076779026\n",
      "Delta(training - validation): \t\t0.0728121098627\n",
      "=========Test on gamma = 0.165=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.813842072409\n",
      "Delta(training - validation): \t\t0.0750468164794\n",
      "=========Test on gamma = 0.167=========\n",
      "Training accuracy:\t\t\t0.888888888889\n",
      "10-fold cross-validation accuracy:\t0.813842072409\n",
      "Delta(training - validation): \t\t0.0750468164794\n",
      "=========Test on gamma = 0.169=========\n",
      "Training accuracy:\t\t\t0.887766554433\n",
      "10-fold cross-validation accuracy:\t0.813842072409\n",
      "Delta(training - validation): \t\t0.0739244820237\n",
      "=========Test on gamma = 0.171=========\n",
      "Training accuracy:\t\t\t0.8911335578\n",
      "10-fold cross-validation accuracy:\t0.813842072409\n",
      "Delta(training - validation): \t\t0.0772914853907\n",
      "=========Test on gamma = 0.173=========\n",
      "Training accuracy:\t\t\t0.8911335578\n",
      "10-fold cross-validation accuracy:\t0.812718476904\n",
      "Delta(training - validation): \t\t0.0784150808964\n",
      "=========Test on gamma = 0.175=========\n",
      "Training accuracy:\t\t\t0.8911335578\n",
      "10-fold cross-validation accuracy:\t0.811594881398\n",
      "Delta(training - validation): \t\t0.079538676402\n",
      "=========Test on gamma = 0.177=========\n",
      "Training accuracy:\t\t\t0.8911335578\n",
      "10-fold cross-validation accuracy:\t0.811594881398\n",
      "Delta(training - validation): \t\t0.079538676402\n",
      "=========Test on gamma = 0.179=========\n",
      "Training accuracy:\t\t\t0.890011223345\n",
      "10-fold cross-validation accuracy:\t0.810471285893\n",
      "Delta(training - validation): \t\t0.0795399374519\n",
      "=========Test on gamma = 0.181=========\n",
      "Training accuracy:\t\t\t0.890011223345\n",
      "10-fold cross-validation accuracy:\t0.810471285893\n",
      "Delta(training - validation): \t\t0.0795399374519\n",
      "=========Test on gamma = 0.183=========\n",
      "Training accuracy:\t\t\t0.890011223345\n",
      "10-fold cross-validation accuracy:\t0.810471285893\n",
      "Delta(training - validation): \t\t0.0795399374519\n",
      "=========Test on gamma = 0.185=========\n",
      "Training accuracy:\t\t\t0.890011223345\n",
      "10-fold cross-validation accuracy:\t0.811594881398\n",
      "Delta(training - validation): \t\t0.0784163419463\n",
      "=========Test on gamma = 0.187=========\n",
      "Training accuracy:\t\t\t0.892255892256\n",
      "10-fold cross-validation accuracy:\t0.811594881398\n",
      "Delta(training - validation): \t\t0.0806610108576\n",
      "=========Test on gamma = 0.189=========\n",
      "Training accuracy:\t\t\t0.892255892256\n",
      "10-fold cross-validation accuracy:\t0.811594881398\n",
      "Delta(training - validation): \t\t0.0806610108576\n",
      "=========Test on gamma = 0.191=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.810458517762\n",
      "Delta(training - validation): \t\t0.0829197089497\n",
      "=========Test on gamma = 0.193=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.810458517762\n",
      "Delta(training - validation): \t\t0.0829197089497\n",
      "=========Test on gamma = 0.195=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.811582113268\n",
      "Delta(training - validation): \t\t0.0817961134441\n",
      "=========Test on gamma = 0.197=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.812693224379\n",
      "Delta(training - validation): \t\t0.0806850023329\n",
      "=========Test on gamma = 0.199=========\n",
      "Training accuracy:\t\t\t0.893378226712\n",
      "10-fold cross-validation accuracy:\t0.812693224379\n",
      "Delta(training - validation): \t\t0.0806850023329\n",
      "=========Test on gamma = 0.201=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.082943700425\n",
      "=========Test on gamma = 0.203=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810433265237\n",
      "Delta(training - validation): \t\t0.0840672959306\n",
      "=========Test on gamma = 0.205=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.082943700425\n",
      "=========Test on gamma = 0.207=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.209=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.811544092612\n",
      "Delta(training - validation): \t\t0.0829564685557\n",
      "=========Test on gamma = 0.211=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.811544092612\n",
      "Delta(training - validation): \t\t0.0829564685557\n",
      "=========Test on gamma = 0.213=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.215=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.217=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.219=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.221=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.223=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0840800640613\n",
      "=========Test on gamma = 0.225=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.082943700425\n",
      "=========Test on gamma = 0.227=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0840660348806\n",
      "=========Test on gamma = 0.229=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.082942439375\n",
      "=========Test on gamma = 0.231=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.814927647259\n",
      "Delta(training - validation): \t\t0.0806952483638\n",
      "=========Test on gamma = 0.233=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.813804051753\n",
      "Delta(training - validation): \t\t0.0818188438694\n",
      "=========Test on gamma = 0.235=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.814927647259\n",
      "Delta(training - validation): \t\t0.0806952483638\n",
      "=========Test on gamma = 0.237=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.813804051753\n",
      "Delta(training - validation): \t\t0.0818188438694\n",
      "=========Test on gamma = 0.239=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.813804051753\n",
      "Delta(training - validation): \t\t0.0818188438694\n",
      "=========Test on gamma = 0.241=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.813804051753\n",
      "Delta(training - validation): \t\t0.0818188438694\n",
      "=========Test on gamma = 0.243=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.813804051753\n",
      "Delta(training - validation): \t\t0.0818188438694\n",
      "=========Test on gamma = 0.245=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.814915162865\n",
      "Delta(training - validation): \t\t0.0807077327583\n",
      "=========Test on gamma = 0.247=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.814915162865\n",
      "Delta(training - validation): \t\t0.0807077327583\n",
      "=========Test on gamma = 0.249=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.814915162865\n",
      "Delta(training - validation): \t\t0.0807077327583\n",
      "=========Test on gamma = 0.251=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.082942439375\n",
      "=========Test on gamma = 0.253=========\n",
      "Training accuracy:\t\t\t0.895622895623\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.082942439375\n",
      "=========Test on gamma = 0.255=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.257=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.259=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.261=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.263=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.265=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.267=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.269=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.271=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.273=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.275=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.0851883693363\n",
      "=========Test on gamma = 0.277=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.279=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.281=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.283=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.285=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.287=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.289=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.291=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.293=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.295=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.813804051753\n",
      "Delta(training - validation): \t\t0.0829411783251\n",
      "=========Test on gamma = 0.297=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812692940642\n",
      "Delta(training - validation): \t\t0.0840522894362\n",
      "=========Test on gamma = 0.299=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812692940642\n",
      "Delta(training - validation): \t\t0.0840522894362\n",
      "=========Test on gamma = 0.301=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812692940642\n",
      "Delta(training - validation): \t\t0.0840522894362\n",
      "=========Test on gamma = 0.303=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.811569345137\n",
      "Delta(training - validation): \t\t0.0851758849418\n",
      "=========Test on gamma = 0.305=========\n",
      "Training accuracy:\t\t\t0.896745230079\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0840647738307\n",
      "=========Test on gamma = 0.307=========\n",
      "Training accuracy:\t\t\t0.897867564534\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0851871082864\n",
      "=========Test on gamma = 0.309=========\n",
      "Training accuracy:\t\t\t0.897867564534\n",
      "10-fold cross-validation accuracy:\t0.812680456248\n",
      "Delta(training - validation): \t\t0.0851871082864\n",
      "=========Test on gamma = 0.311=========\n",
      "Training accuracy:\t\t\t0.897867564534\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.086310703792\n",
      "=========Test on gamma = 0.313=========\n",
      "Training accuracy:\t\t\t0.897867564534\n",
      "10-fold cross-validation accuracy:\t0.811556860742\n",
      "Delta(training - validation): \t\t0.086310703792\n",
      "=========Test on gamma = 0.315=========\n",
      "Training accuracy:\t\t\t0.897867564534\n",
      "10-fold cross-validation accuracy:\t0.810420497106\n",
      "Delta(training - validation): \t\t0.0874470674283\n",
      "=========Test on gamma = 0.317=========\n",
      "Training accuracy:\t\t\t0.897867564534\n",
      "10-fold cross-validation accuracy:\t0.8092969016\n",
      "Delta(training - validation): \t\t0.088570662934\n",
      "=========Test on gamma = 0.319=========\n",
      "Training accuracy:\t\t\t0.89898989899\n",
      "10-fold cross-validation accuracy:\t0.8092969016\n",
      "Delta(training - validation): \t\t0.0896929973896\n",
      "=========Test on gamma = 0.321=========\n",
      "Training accuracy:\t\t\t0.89898989899\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.090829361026\n",
      "=========Test on gamma = 0.323=========\n",
      "Training accuracy:\t\t\t0.89898989899\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.090829361026\n",
      "=========Test on gamma = 0.325=========\n",
      "Training accuracy:\t\t\t0.89898989899\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0919529565316\n",
      "=========Test on gamma = 0.327=========\n",
      "Training accuracy:\t\t\t0.89898989899\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0919529565316\n",
      "=========Test on gamma = 0.329=========\n",
      "Training accuracy:\t\t\t0.89898989899\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0919529565316\n",
      "=========Test on gamma = 0.331=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0953199598986\n",
      "=========Test on gamma = 0.333=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0953199598986\n",
      "=========Test on gamma = 0.335=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0953186988487\n",
      "=========Test on gamma = 0.337=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0953186988487\n",
      "=========Test on gamma = 0.339=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0953186988487\n",
      "=========Test on gamma = 0.341=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0953186988487\n",
      "=========Test on gamma = 0.343=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0953186988487\n",
      "=========Test on gamma = 0.345=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0964410333043\n",
      "=========Test on gamma = 0.347=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.808160537964\n",
      "Delta(training - validation): \t\t0.0964410333043\n",
      "=========Test on gamma = 0.349=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0975646288099\n",
      "=========Test on gamma = 0.351=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.807036942458\n",
      "Delta(training - validation): \t\t0.0975646288099\n",
      "=========Test on gamma = 0.353=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.355=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.357=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.359=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.361=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.363=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.365=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805900578822\n",
      "Delta(training - validation): \t\t0.099823326902\n",
      "=========Test on gamma = 0.367=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.804776983316\n",
      "Delta(training - validation): \t\t0.100946922408\n",
      "=========Test on gamma = 0.369=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.804776983316\n",
      "Delta(training - validation): \t\t0.100946922408\n",
      "=========Test on gamma = 0.371=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.373=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.375=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.377=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.379=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.381=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.802529792305\n",
      "Delta(training - validation): \t\t0.102071778963\n",
      "=========Test on gamma = 0.383=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.802529792305\n",
      "Delta(training - validation): \t\t0.102071778963\n",
      "=========Test on gamma = 0.385=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.802529792305\n",
      "Delta(training - validation): \t\t0.102071778963\n",
      "=========Test on gamma = 0.387=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.802529792305\n",
      "Delta(training - validation): \t\t0.102071778963\n",
      "=========Test on gamma = 0.389=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.802529792305\n",
      "Delta(training - validation): \t\t0.102071778963\n",
      "=========Test on gamma = 0.391=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.393=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.395=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.397=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.100948183458\n",
      "=========Test on gamma = 0.399=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.0998258490019\n",
      "=========Test on gamma = 0.401=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.0998258490019\n",
      "=========Test on gamma = 0.403=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803653387811\n",
      "Delta(training - validation): \t\t0.0998258490019\n",
      "=========Test on gamma = 0.405=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.100936960113\n",
      "=========Test on gamma = 0.407=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0998146256573\n",
      "=========Test on gamma = 0.409=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0998146256573\n",
      "=========Test on gamma = 0.411=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0998146256573\n",
      "=========Test on gamma = 0.413=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0986922912017\n",
      "=========Test on gamma = 0.415=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0986922912017\n",
      "=========Test on gamma = 0.417=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0986922912017\n",
      "=========Test on gamma = 0.419=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.8025422767\n",
      "Delta(training - validation): \t\t0.0986922912017\n",
      "=========Test on gamma = 0.421=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0964451001904\n",
      "=========Test on gamma = 0.423=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0964451001904\n",
      "=========Test on gamma = 0.425=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0964451001904\n",
      "=========Test on gamma = 0.427=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0964451001904\n",
      "=========Test on gamma = 0.429=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0964451001904\n",
      "=========Test on gamma = 0.431=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.097568695696\n",
      "=========Test on gamma = 0.433=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.097568695696\n",
      "=========Test on gamma = 0.435=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.097568695696\n",
      "=========Test on gamma = 0.437=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.097568695696\n",
      "=========Test on gamma = 0.439=========\n",
      "Training accuracy:\t\t\t0.901234567901\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.097568695696\n",
      "=========Test on gamma = 0.441=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.443=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.445=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.447=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.449=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.451=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.453=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0986910301517\n",
      "=========Test on gamma = 0.455=========\n",
      "Training accuracy:\t\t\t0.902356902357\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0975674346461\n",
      "=========Test on gamma = 0.457=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0986897691018\n",
      "=========Test on gamma = 0.459=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0998133646074\n",
      "=========Test on gamma = 0.461=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0998133646074\n",
      "=========Test on gamma = 0.463=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0998133646074\n",
      "=========Test on gamma = 0.465=========\n",
      "Training accuracy:\t\t\t0.903479236813\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.0998133646074\n",
      "=========Test on gamma = 0.467=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.100935699063\n",
      "=========Test on gamma = 0.469=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.100935699063\n",
      "=========Test on gamma = 0.471=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.100935699063\n",
      "=========Test on gamma = 0.473=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.100935699063\n",
      "=========Test on gamma = 0.475=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.803665872205\n",
      "Delta(training - validation): \t\t0.100935699063\n",
      "=========Test on gamma = 0.477=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.479=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.481=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.483=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.485=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.487=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.489=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.491=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.493=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.495=========\n",
      "Training accuracy:\t\t\t0.904601571268\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.0998121035574\n",
      "=========Test on gamma = 0.497=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.804789467711\n",
      "Delta(training - validation): \t\t0.100934438013\n",
      "=========Test on gamma = 0.499=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.805913063216\n",
      "Delta(training - validation): \t\t0.0998108425075\n"
     ]
    }
   ],
   "source": [
    "for gamma in np.arange(0.001, 0.5, 0.002): \n",
    "    print '=========Test on gamma = %s=========' % gamma\n",
    "    test_model(SVC(gamma=gamma, C = 10), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.concat([raw_dtrain, raw_dtest])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1309, 12)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    446.000000\n",
       "Survived         0.383838\n",
       "Pclass           2.308642\n",
       "Age             29.699118\n",
       "SibSp            0.523008\n",
       "Parch            0.381594\n",
       "Fare            32.204208\n",
       "dtype: float64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtrain.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    257.353842\n",
       "Survived         0.486592\n",
       "Pclass           0.836071\n",
       "Age             14.526497\n",
       "SibSp            1.102743\n",
       "Parch            0.806057\n",
       "Fare            49.693429\n",
       "dtype: float64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtrain.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    1100.500000\n",
       "Pclass            2.265550\n",
       "Age              30.272590\n",
       "SibSp             0.447368\n",
       "Parch             0.392344\n",
       "Fare             35.627188\n",
       "dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtest.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PassengerId    120.810458\n",
       "Pclass           0.841838\n",
       "Age             14.181209\n",
       "SibSp            0.896760\n",
       "Parch            0.981429\n",
       "Fare            55.907576\n",
       "dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtest.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'110152',\n",
       " '110413',\n",
       " '110465',\n",
       " '110469',\n",
       " '110489',\n",
       " '110564',\n",
       " '110813',\n",
       " '111163',\n",
       " '111240',\n",
       " '111320',\n",
       " '111361',\n",
       " '111369',\n",
       " '111426',\n",
       " '111427',\n",
       " '111428',\n",
       " '112050',\n",
       " '112051',\n",
       " '112052',\n",
       " '112053',\n",
       " '112058',\n",
       " '112059',\n",
       " '112277',\n",
       " '112377',\n",
       " '112378',\n",
       " '112379',\n",
       " '112901',\n",
       " '113028',\n",
       " '113038',\n",
       " '113043',\n",
       " '113044',\n",
       " '113050',\n",
       " '113051',\n",
       " '113054',\n",
       " '113055',\n",
       " '113056',\n",
       " '113059',\n",
       " '113501',\n",
       " '113503',\n",
       " '113505',\n",
       " '113509',\n",
       " '113510',\n",
       " '113514',\n",
       " '113572',\n",
       " '113760',\n",
       " '113767',\n",
       " '113773',\n",
       " '113776',\n",
       " '113778',\n",
       " '113780',\n",
       " '113781',\n",
       " '113783',\n",
       " '113784',\n",
       " '113786',\n",
       " '113787',\n",
       " '113788',\n",
       " '113789',\n",
       " '113790',\n",
       " '113791',\n",
       " '113792',\n",
       " '113794',\n",
       " '113795',\n",
       " '113796',\n",
       " '113798',\n",
       " '113800',\n",
       " '113801',\n",
       " '113803',\n",
       " '113804',\n",
       " '113806',\n",
       " '113807',\n",
       " '11668',\n",
       " '11751',\n",
       " '11752',\n",
       " '11753',\n",
       " '11755',\n",
       " '11765',\n",
       " '11767',\n",
       " '11769',\n",
       " '11770',\n",
       " '11771',\n",
       " '11774',\n",
       " '11778',\n",
       " '11813',\n",
       " '11967',\n",
       " '1222',\n",
       " '12233',\n",
       " '12460',\n",
       " '12749',\n",
       " '13049',\n",
       " '13050',\n",
       " '13213',\n",
       " '13214',\n",
       " '13236',\n",
       " '13502',\n",
       " '13507',\n",
       " '13508',\n",
       " '13509',\n",
       " '13567',\n",
       " '13568',\n",
       " '13695',\n",
       " '13905',\n",
       " '14311',\n",
       " '14312',\n",
       " '14313',\n",
       " '14973',\n",
       " '1601',\n",
       " '16966',\n",
       " '16988',\n",
       " '17421',\n",
       " '17453',\n",
       " '17463',\n",
       " '17464',\n",
       " '17465',\n",
       " '17466',\n",
       " '17474',\n",
       " '17475',\n",
       " '17764',\n",
       " '17765',\n",
       " '17770',\n",
       " '19877',\n",
       " '19924',\n",
       " '19928',\n",
       " '19943',\n",
       " '19947',\n",
       " '19950',\n",
       " '19952',\n",
       " '19972',\n",
       " '19988',\n",
       " '19996',\n",
       " '2003',\n",
       " '211535',\n",
       " '211536',\n",
       " '21228',\n",
       " '21332',\n",
       " '21440',\n",
       " '218629',\n",
       " '219533',\n",
       " '220367',\n",
       " '220844',\n",
       " '220845',\n",
       " '2223',\n",
       " '223596',\n",
       " '226593',\n",
       " '226875',\n",
       " '228414',\n",
       " '229236',\n",
       " '230080',\n",
       " '230136',\n",
       " '230433',\n",
       " '230434',\n",
       " '231919',\n",
       " '231945',\n",
       " '233478',\n",
       " '233639',\n",
       " '233734',\n",
       " '233866',\n",
       " '234360',\n",
       " '234604',\n",
       " '234686',\n",
       " '234818',\n",
       " '235509',\n",
       " '236171',\n",
       " '236852',\n",
       " '236853',\n",
       " '236854',\n",
       " '237216',\n",
       " '237249',\n",
       " '237393',\n",
       " '237442',\n",
       " '237565',\n",
       " '237668',\n",
       " '237670',\n",
       " '237671',\n",
       " '237734',\n",
       " '237735',\n",
       " '237736',\n",
       " '237789',\n",
       " '237798',\n",
       " '239059',\n",
       " '239853',\n",
       " '239854',\n",
       " '239855',\n",
       " '239856',\n",
       " '239865',\n",
       " '240261',\n",
       " '240276',\n",
       " '24065',\n",
       " '240929',\n",
       " '24160',\n",
       " '242963',\n",
       " '243847',\n",
       " '243880',\n",
       " '244252',\n",
       " '244270',\n",
       " '244278',\n",
       " '244310',\n",
       " '244346',\n",
       " '244358',\n",
       " '244360',\n",
       " '244361',\n",
       " '244367',\n",
       " '244368',\n",
       " '244373',\n",
       " '248659',\n",
       " '248698',\n",
       " '248706',\n",
       " '248723',\n",
       " '248726',\n",
       " '248727',\n",
       " '248731',\n",
       " '248733',\n",
       " '248734',\n",
       " '248738',\n",
       " '248740',\n",
       " '248744',\n",
       " '248746',\n",
       " '248747',\n",
       " '250643',\n",
       " '250644',\n",
       " '250646',\n",
       " '250647',\n",
       " '250648',\n",
       " '250649',\n",
       " '250650',\n",
       " '250651',\n",
       " '250652',\n",
       " '250653',\n",
       " '250655',\n",
       " '2543',\n",
       " '2620',\n",
       " '2621',\n",
       " '2622',\n",
       " '2623',\n",
       " '2624',\n",
       " '2625',\n",
       " '2626',\n",
       " '2627',\n",
       " '2628',\n",
       " '2629',\n",
       " '2631',\n",
       " '26360',\n",
       " '2641',\n",
       " '2647',\n",
       " '2648',\n",
       " '2649',\n",
       " '2650',\n",
       " '2651',\n",
       " '2652',\n",
       " '2653',\n",
       " '2654',\n",
       " '2655',\n",
       " '2656',\n",
       " '2657',\n",
       " '2658',\n",
       " '2659',\n",
       " '2660',\n",
       " '2661',\n",
       " '2662',\n",
       " '2663',\n",
       " '2664',\n",
       " '2665',\n",
       " '2666',\n",
       " '2667',\n",
       " '2668',\n",
       " '2669',\n",
       " '2670',\n",
       " '26707',\n",
       " '2671',\n",
       " '2672',\n",
       " '2673',\n",
       " '2674',\n",
       " '2675',\n",
       " '2676',\n",
       " '2677',\n",
       " '2678',\n",
       " '2679',\n",
       " '2680',\n",
       " '2681',\n",
       " '2682',\n",
       " '2683',\n",
       " '2684',\n",
       " '2685',\n",
       " '2686',\n",
       " '2687',\n",
       " '2688',\n",
       " '2689',\n",
       " '2690',\n",
       " '2691',\n",
       " '2692',\n",
       " '2693',\n",
       " '2694',\n",
       " '2695',\n",
       " '2696',\n",
       " '2697',\n",
       " '2698',\n",
       " '2699',\n",
       " '2700',\n",
       " '27042',\n",
       " '27267',\n",
       " '27849',\n",
       " '28004',\n",
       " '28034',\n",
       " '28133',\n",
       " '28134',\n",
       " '28206',\n",
       " '28213',\n",
       " '28220',\n",
       " '28221',\n",
       " '28228',\n",
       " '28403',\n",
       " '28404',\n",
       " '28424',\n",
       " '28425',\n",
       " '28551',\n",
       " '28664',\n",
       " '28665',\n",
       " '28666',\n",
       " '29011',\n",
       " '2908',\n",
       " '29103',\n",
       " '29104',\n",
       " '29105',\n",
       " '29106',\n",
       " '29107',\n",
       " '29108',\n",
       " '2926',\n",
       " '29750',\n",
       " '29751',\n",
       " '3101264',\n",
       " '3101265',\n",
       " '3101266',\n",
       " '3101267',\n",
       " '3101276',\n",
       " '3101277',\n",
       " '3101278',\n",
       " '3101281',\n",
       " '3101295',\n",
       " '3101296',\n",
       " '3101297',\n",
       " '3101298',\n",
       " '31027',\n",
       " '31028',\n",
       " '312991',\n",
       " '312992',\n",
       " '312993',\n",
       " '31418',\n",
       " '315037',\n",
       " '315082',\n",
       " '315083',\n",
       " '315084',\n",
       " '315085',\n",
       " '315086',\n",
       " '315087',\n",
       " '315088',\n",
       " '315089',\n",
       " '315090',\n",
       " '315091',\n",
       " '315092',\n",
       " '315093',\n",
       " '315094',\n",
       " '315095',\n",
       " '315096',\n",
       " '315097',\n",
       " '315098',\n",
       " '315151',\n",
       " '315152',\n",
       " '315153',\n",
       " '315154',\n",
       " '32302',\n",
       " '323592',\n",
       " '323951',\n",
       " '324669',\n",
       " '329944',\n",
       " '330844',\n",
       " '330877',\n",
       " '330909',\n",
       " '330910',\n",
       " '330911',\n",
       " '330919',\n",
       " '330920',\n",
       " '330923',\n",
       " '330924',\n",
       " '330931',\n",
       " '330932',\n",
       " '330935',\n",
       " '330958',\n",
       " '330959',\n",
       " '330963',\n",
       " '330968',\n",
       " '330971',\n",
       " '330972',\n",
       " '330979',\n",
       " '330980',\n",
       " '334912',\n",
       " '334914',\n",
       " '334915',\n",
       " '335097',\n",
       " '335432',\n",
       " '335677',\n",
       " '33638',\n",
       " '336439',\n",
       " '3410',\n",
       " '3411',\n",
       " '341826',\n",
       " '34218',\n",
       " '342441',\n",
       " '342684',\n",
       " '342712',\n",
       " '342826',\n",
       " '343095',\n",
       " '343120',\n",
       " '343271',\n",
       " '343275',\n",
       " '343276',\n",
       " '345364',\n",
       " '345498',\n",
       " '345501',\n",
       " '345572',\n",
       " '345763',\n",
       " '345764',\n",
       " '345765',\n",
       " '345767',\n",
       " '345768',\n",
       " '345769',\n",
       " '345770',\n",
       " '345771',\n",
       " '345773',\n",
       " '345774',\n",
       " '345775',\n",
       " '345777',\n",
       " '345778',\n",
       " '345779',\n",
       " '345780',\n",
       " '345781',\n",
       " '345783',\n",
       " '3460',\n",
       " '3470',\n",
       " '347054',\n",
       " '347060',\n",
       " '347061',\n",
       " '347062',\n",
       " '347063',\n",
       " '347064',\n",
       " '347065',\n",
       " '347066',\n",
       " '347067',\n",
       " '347068',\n",
       " '347069',\n",
       " '347070',\n",
       " '347071',\n",
       " '347072',\n",
       " '347073',\n",
       " '347074',\n",
       " '347075',\n",
       " '347076',\n",
       " '347077',\n",
       " '347078',\n",
       " '347079',\n",
       " '347080',\n",
       " '347081',\n",
       " '347082',\n",
       " '347083',\n",
       " '347085',\n",
       " '347086',\n",
       " '347087',\n",
       " '347088',\n",
       " '347089',\n",
       " '347090',\n",
       " '347091',\n",
       " '3474',\n",
       " '347464',\n",
       " '347465',\n",
       " '347466',\n",
       " '347467',\n",
       " '347468',\n",
       " '347469',\n",
       " '347470',\n",
       " '347471',\n",
       " '347742',\n",
       " '347743',\n",
       " '348121',\n",
       " '348122',\n",
       " '348123',\n",
       " '348124',\n",
       " '348125',\n",
       " '349201',\n",
       " '349202',\n",
       " '349203',\n",
       " '349204',\n",
       " '349205',\n",
       " '349206',\n",
       " '349207',\n",
       " '349208',\n",
       " '349209',\n",
       " '349210',\n",
       " '349211',\n",
       " '349212',\n",
       " '349213',\n",
       " '349214',\n",
       " '349215',\n",
       " '349216',\n",
       " '349217',\n",
       " '349218',\n",
       " '349219',\n",
       " '349220',\n",
       " '349221',\n",
       " '349222',\n",
       " '349223',\n",
       " '349224',\n",
       " '349225',\n",
       " '349226',\n",
       " '349227',\n",
       " '349228',\n",
       " '349229',\n",
       " '349230',\n",
       " '349231',\n",
       " '349232',\n",
       " '349233',\n",
       " '349234',\n",
       " '349235',\n",
       " '349236',\n",
       " '349237',\n",
       " '349238',\n",
       " '349239',\n",
       " '349240',\n",
       " '349241',\n",
       " '349242',\n",
       " '349243',\n",
       " '349244',\n",
       " '349245',\n",
       " '349246',\n",
       " '349247',\n",
       " '349248',\n",
       " '349249',\n",
       " '349250',\n",
       " '349251',\n",
       " '349252',\n",
       " '349253',\n",
       " '349254',\n",
       " '349255',\n",
       " '349256',\n",
       " '349257',\n",
       " '349909',\n",
       " '349910',\n",
       " '349911',\n",
       " '349912',\n",
       " '350025',\n",
       " '350026',\n",
       " '350029',\n",
       " '350033',\n",
       " '350034',\n",
       " '350035',\n",
       " '350036',\n",
       " '350042',\n",
       " '350043',\n",
       " '350045',\n",
       " '350046',\n",
       " '350047',\n",
       " '350048',\n",
       " '350050',\n",
       " '350052',\n",
       " '350053',\n",
       " '350054',\n",
       " '350060',\n",
       " '350403',\n",
       " '350404',\n",
       " '350405',\n",
       " '350406',\n",
       " '350407',\n",
       " '350408',\n",
       " '350409',\n",
       " '350410',\n",
       " '350416',\n",
       " '350417',\n",
       " '35273',\n",
       " '35281',\n",
       " '35851',\n",
       " '35852',\n",
       " '358585',\n",
       " '359306',\n",
       " '359309',\n",
       " '36209',\n",
       " '362316',\n",
       " '363272',\n",
       " '363291',\n",
       " '363294',\n",
       " '363592',\n",
       " '363611',\n",
       " '364498',\n",
       " '364499',\n",
       " '364500',\n",
       " '364506',\n",
       " '364511',\n",
       " '364512',\n",
       " '364516',\n",
       " '364846',\n",
       " '364848',\n",
       " '364849',\n",
       " '364850',\n",
       " '364851',\n",
       " '364856',\n",
       " '364858',\n",
       " '364859',\n",
       " '365222',\n",
       " '365226',\n",
       " '365235',\n",
       " '365237',\n",
       " '36568',\n",
       " '366713',\n",
       " '367226',\n",
       " '367227',\n",
       " '367228',\n",
       " '367229',\n",
       " '367230',\n",
       " '367231',\n",
       " '367232',\n",
       " '367655',\n",
       " '368323',\n",
       " '368364',\n",
       " '368402',\n",
       " '368573',\n",
       " '36864',\n",
       " '36865',\n",
       " '36866',\n",
       " '368702',\n",
       " '368703',\n",
       " '368783',\n",
       " '36928',\n",
       " '36947',\n",
       " '36963',\n",
       " '36967',\n",
       " '36973',\n",
       " '3701',\n",
       " '370129',\n",
       " '370365',\n",
       " '370368',\n",
       " '370369',\n",
       " '370370',\n",
       " '370371',\n",
       " '370372',\n",
       " '370373',\n",
       " '370374',\n",
       " '370375',\n",
       " '370376',\n",
       " '370377',\n",
       " '371060',\n",
       " '371109',\n",
       " '371110',\n",
       " '371362',\n",
       " '372622',\n",
       " '373450',\n",
       " '374746',\n",
       " '374887',\n",
       " '374910',\n",
       " '376563',\n",
       " '376564',\n",
       " '376566',\n",
       " '382649',\n",
       " '382650',\n",
       " '382651',\n",
       " '382652',\n",
       " '382653',\n",
       " '383121',\n",
       " '383123',\n",
       " '383162',\n",
       " '384461',\n",
       " '386525',\n",
       " '392091',\n",
       " '392092',\n",
       " '392095',\n",
       " '392096',\n",
       " '394140',\n",
       " '4133',\n",
       " '4134',\n",
       " '4135',\n",
       " '4136',\n",
       " '4137',\n",
       " '4138',\n",
       " '4579',\n",
       " '54636',\n",
       " '5727',\n",
       " '65303',\n",
       " '65304',\n",
       " '65305',\n",
       " '65306',\n",
       " '6563',\n",
       " '680',\n",
       " '693',\n",
       " '694',\n",
       " '695',\n",
       " '7266',\n",
       " '7267',\n",
       " '7534',\n",
       " '7538',\n",
       " '7540',\n",
       " '7545',\n",
       " '7546',\n",
       " '7548',\n",
       " '7552',\n",
       " '7553',\n",
       " '7598',\n",
       " '7935',\n",
       " '8471',\n",
       " '8475',\n",
       " '9232',\n",
       " '9234',\n",
       " 'A',\n",
       " 'A./5',\n",
       " 'A.5',\n",
       " 'A/4',\n",
       " 'A/5',\n",
       " 'A/S',\n",
       " 'A4',\n",
       " 'AQ/3',\n",
       " 'AQ/4',\n",
       " 'C',\n",
       " 'C.A',\n",
       " 'C.A./SOTON',\n",
       " 'CA',\n",
       " 'F.C',\n",
       " 'F.C.C',\n",
       " 'Fa',\n",
       " 'LINE',\n",
       " 'LP',\n",
       " 'P/PP',\n",
       " 'PC',\n",
       " 'PP',\n",
       " 'S.C./A.4',\n",
       " 'S.C./PARIS',\n",
       " 'S.O./P.P',\n",
       " 'S.O.C',\n",
       " 'S.O.P',\n",
       " 'S.P',\n",
       " 'S.W./PP',\n",
       " 'SC',\n",
       " 'SC/A.3',\n",
       " 'SC/A4',\n",
       " 'SC/AH',\n",
       " 'SC/PARIS',\n",
       " 'SC/Paris',\n",
       " 'SCO/W',\n",
       " 'SO/C',\n",
       " 'SOTON/O.Q',\n",
       " 'SOTON/O2',\n",
       " 'SOTON/OQ',\n",
       " 'STON/O',\n",
       " 'STON/O2',\n",
       " 'STON/OQ',\n",
       " 'SW/PP',\n",
       " 'W./C',\n",
       " 'W.E.P',\n",
       " 'W/C',\n",
       " 'WE/P'}"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(dataset['Ticket'].map(lambda x: x.split()[0].strip('.')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    ">>> from sklearn import svm, grid_search, datasets\n",
    ">>> iris = datasets.load_iris()\n",
    ">>> parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    ">>> svr = svm.SVC()\n",
    ">>> clf = grid_search.GridSearchCV(svr, parameters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param =  [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "  tol=0.001, verbose=False),\n",
       "       fit_params={}, iid=True, n_jobs=-1,\n",
       "       param_grid=[{'kernel': ['rbf'], 'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001]}, {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, scoring=None, verbose=0)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ">>> clf = grid_search.GridSearchCV(svr, param, n_jobs=-1)\n",
    ">>> clf.fit(iris.data, iris.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cv': None,\n",
       " 'error_score': 'raise',\n",
       " 'estimator': SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "   decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
       "   max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "   tol=0.001, verbose=False),\n",
       " 'estimator__C': 1.0,\n",
       " 'estimator__cache_size': 200,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__coef0': 0.0,\n",
       " 'estimator__decision_function_shape': None,\n",
       " 'estimator__degree': 3,\n",
       " 'estimator__gamma': 'auto',\n",
       " 'estimator__kernel': 'rbf',\n",
       " 'estimator__max_iter': -1,\n",
       " 'estimator__probability': False,\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__shrinking': True,\n",
       " 'estimator__tol': 0.001,\n",
       " 'estimator__verbose': False,\n",
       " 'fit_params': {},\n",
       " 'iid': True,\n",
       " 'n_jobs': -1,\n",
       " 'param_grid': [{'C': [1, 10, 100, 1000],\n",
       "   'gamma': [0.001, 0.0001],\n",
       "   'kernel': ['rbf']},\n",
       "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']}],\n",
       " 'pre_dispatch': '2*n_jobs',\n",
       " 'refit': True,\n",
       " 'scoring': None,\n",
       " 'verbose': 0}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model with rank: 1\n",
      "Mean validation score: 0.987 (std: 0.018)\n",
      "Parameters: {'kernel': 'rbf', 'C': 1000, 'gamma': 0.001}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.980 (std: 0.016)\n",
      "Parameters: {'kernel': 'linear', 'C': 1}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.973 (std: 0.009)\n",
      "Parameters: {'kernel': 'rbf', 'C': 100, 'gamma': 0.001}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report(clf.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 1000, 'gamma': 0.001, 'kernel': 'rbf'}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__call__',\n",
       " '__class__',\n",
       " '__closure__',\n",
       " '__code__',\n",
       " '__defaults__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__doc__',\n",
       " '__format__',\n",
       " '__get__',\n",
       " '__getattribute__',\n",
       " '__globals__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__module__',\n",
       " '__name__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " 'func_closure',\n",
       " 'func_code',\n",
       " 'func_defaults',\n",
       " 'func_dict',\n",
       " 'func_doc',\n",
       " 'func_globals',\n",
       " 'func_name']"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scorer_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Function that wraps estimator.score'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scorer_.__doc__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "RandomizedSearchCV took 4.03 seconds for 20 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.922 (std: 0.014)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 5, 'min_samples_split': 2, 'criterion': 'gini', 'max_features': 7, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.920 (std: 0.010)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 6, 'min_samples_split': 5, 'criterion': 'gini', 'max_features': 8, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.912 (std: 0.015)\n",
      "Parameters: {'bootstrap': True, 'min_samples_leaf': 4, 'min_samples_split': 1, 'criterion': 'gini', 'max_features': 5, 'max_depth': None}\n",
      "\n",
      "GridSearchCV took 36.10 seconds for 216 candidate parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.937 (std: 0.004)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'gini', 'max_features': 10, 'max_depth': None}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.936 (std: 0.004)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 3, 'criterion': 'gini', 'max_features': 3, 'max_depth': None}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.932 (std: 0.009)\n",
      "Parameters: {'bootstrap': False, 'min_samples_leaf': 1, 'min_samples_split': 1, 'criterion': 'entropy', 'max_features': 10, 'max_depth': None}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(__doc__)\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from scipy.stats import randint as sp_randint\n",
    "\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# get some data\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "# build a classifier\n",
    "clf = RandomForestClassifier(n_estimators=20)\n",
    "\n",
    "\n",
    "# Utility function to report best scores\n",
    "def report(grid_scores, n_top=3):\n",
    "    top_scores = sorted(grid_scores, key=itemgetter(1), reverse=True)[:n_top]\n",
    "    for i, score in enumerate(top_scores):\n",
    "        print(\"Model with rank: {0}\".format(i + 1))\n",
    "        print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "              score.mean_validation_score,\n",
    "              np.std(score.cv_validation_scores)))\n",
    "        print(\"Parameters: {0}\".format(score.parameters))\n",
    "        print(\"\")\n",
    "\n",
    "\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 11),\n",
    "              \"min_samples_split\": sp_randint(1, 11),\n",
    "              \"min_samples_leaf\": sp_randint(1, 11),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X, y)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "report(random_search.grid_scores_)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_grid = {\"max_depth\": [3, None],\n",
    "              \"max_features\": [1, 3, 10],\n",
    "              \"min_samples_split\": [1, 3, 10],\n",
    "              \"min_samples_leaf\": [1, 3, 10],\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run grid search\n",
    "grid_search = GridSearchCV(clf, param_grid=param_grid)\n",
    "start = time()\n",
    "grid_search.fit(X, y)\n",
    "\n",
    "print(\"GridSearchCV took %.2f seconds for %d candidate parameter settings.\"\n",
    "      % (time() - start, len(grid_search.grid_scores_)))\n",
    "report(grid_search.grid_scores_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-85-c0adbf7e0145>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgrid_search\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'module' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "grid_search.score(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
