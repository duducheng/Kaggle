{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To improve Titanic accuracy\n",
    "### --By Jiancheng\n",
    "Work on [Kaggle Titanic](https://www.kaggle.com/c/titanic)\n",
    "\n",
    "Start on 2016/03/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary:\n",
    "1. Data processing module changes\n",
    "1. Testing separate model on SVC, GBC, etc\n",
    "1. Voting test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pylab as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_dtrain = pd.read_csv('data/train.csv')\n",
    "raw_dtest = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn import cross_validation\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier,GradientBoostingClassifier, RandomForestClassifier, ExtraTreesClassifier, VotingClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex  Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male   22      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female   38      1   \n",
       "2                             Heikkinen, Miss. Laina  female   26      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female   35      1   \n",
       "4                           Allen, Mr. William Henry    male   35      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtrain.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add new features into data processing module:\n",
    "1. Delete 'Family' features, replace with the original features 'SibSp' and 'Parch'\n",
    "1. Normalizing the features on the training and testing data set\n",
    "1. Delete 'Title feature'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_data(in_df, mean_train = None, std_train = None, training = False):\n",
    "    df = in_df.copy()\n",
    "\n",
    "    age_average = {' Major': 48.5, ' the Countess': 33.0, ' Don': 40.0, ' Sir': 49.0, ' Miss': 21.773972602739725, \n",
    "                   ' Mlle': 24.0, ' Mrs': 35.898148148148145, ' Capt': 70.0, ' Rev': 43.166666666666664, ' Dr': 42.0, \n",
    "                   ' Master': 4.5741666666666667, ' Mr': 32.368090452261306, ' Ms': 28.0, ' Jonkheer': 38.0, \n",
    "                   ' Col': 58.0, ' Lady': 48.0, ' Mme': 24.0, ' Dona': 39}\n",
    "    title_convert = {' Major': 'Army', ' the Countess': 'Upper', ' Don': 'Mr', ' Miss': 'Miss', ' Sir': 'Upper', ' Mlle': 'Upper', \n",
    "                        ' Mrs': 'Mrs', ' Capt': 'Upper', ' Rev': 'Rev', ' Dr': 'Dr', ' Master': 'Master', ' Mr': 'Mr', ' Ms': 'Miss', \n",
    "                        ' Jonkheer': 'Upper', ' Col': 'Army', ' Lady': 'Upper', ' Mme': 'Upper', ' Dona': 'Upper'}\n",
    "    \n",
    "    # feature transformation\n",
    "#     df['Family'] = df['SibSp'] + df['Parch']\n",
    "    df['orgTitle'] = df['Name'].map(lambda x: x.split(',')[1].split('.')[0]) # extract \"Title\" from \"Name\"\n",
    "    df['Title'] = df['orgTitle'].map(lambda x: title_convert[x]) # then also merge some rare Title into commom ones \n",
    "    df['Cabin'] = df['Cabin'].map(lambda x: str(x)[0])\n",
    "    df['Cabin'] = df['Cabin'].map(lambda x: x if x != 'T' else 'n')\n",
    "    df['Sex'] = df['Sex'].map(lambda x: 0 if x == 'male' else 1) # male: 0 female: 1\n",
    "    \n",
    "    # deal with NaN and 0\n",
    "    df['Fare'] = df['Fare'].groupby(df['Pclass']).apply(lambda g: g.fillna(g.mean())) # the average Pclass fare\n",
    "    df['Fare'] = df['Fare'].groupby(df['Pclass']).apply(lambda g: g.replace(0, g.mean())) # the average Pclass fare\n",
    "    df['Embarked'] = df['Embarked'].fillna('n')  # the most frequent item\n",
    "    df['Age'] = df['Age'].groupby(df['orgTitle']).apply(lambda g: g.fillna(age_average[g.name])) # average age of Title\n",
    "    \n",
    "    # normalization\n",
    "    if training:\n",
    "        mean_train = df[['Age','SibSp','Parch','Fare']].mean()\n",
    "        std_train = df[['Age','SibSp','Parch','Fare']].std()\n",
    "        \n",
    "    df[['Age','SibSp','Parch','Fare']]= (df[['Age','SibSp','Parch','Fare']]- mean_train) / std_train\n",
    "    \n",
    "    \n",
    "    # transfer category feature into dummy feature   \n",
    "    df = pd.concat([df, pd.get_dummies(df['Embarked'], prefix='Embarked')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['Pclass'], prefix='Pclass')], axis=1)\n",
    "    df = pd.concat([df, pd.get_dummies(df['Cabin'], prefix='Cabin')], axis=1)\n",
    "#     df = pd.concat([df, pd.get_dummies(df['Title'], prefix='Title')], axis=1)\n",
    "    \n",
    "    # drop features we don't need \n",
    "    df = df.drop(['orgTitle'], axis = 1)\n",
    "#     df = df.drop(['Embarked', 'Name', 'SibSp', 'Parch', 'Ticket', 'PassengerId', 'Pclass', 'Cabin','Title'], axis = 1)  \n",
    "    df = df.drop(['Embarked', 'Name', 'Ticket', 'PassengerId', 'Pclass', 'Cabin','Title'], axis = 1) \n",
    "    return df, mean_train, std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Survived      0\n",
      "Sex           0\n",
      "Age           0\n",
      "SibSp         0\n",
      "Parch         0\n",
      "Fare          0\n",
      "Embarked_C    0\n",
      "Embarked_Q    0\n",
      "Embarked_S    0\n",
      "Embarked_n    0\n",
      "Pclass_1      0\n",
      "Pclass_2      0\n",
      "Pclass_3      0\n",
      "Cabin_A       0\n",
      "Cabin_B       0\n",
      "Cabin_C       0\n",
      "Cabin_D       0\n",
      "Cabin_E       0\n",
      "Cabin_F       0\n",
      "Cabin_G       0\n",
      "Cabin_n       0\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Embarked_n</th>\n",
       "      <th>...</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.584059</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.515736</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.621016</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.772917</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.282790</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.502152</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>0.406983</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.395064</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.499636</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Sex       Age     SibSp     Parch      Fare  Embarked_C  \\\n",
       "0         0    0 -0.584059  0.432550 -0.473408 -0.515736           0   \n",
       "1         1    1  0.621016  0.432550 -0.473408  0.772917           1   \n",
       "2         1    1 -0.282790 -0.474279 -0.473408 -0.502152           0   \n",
       "3         1    1  0.395064  0.432550 -0.473408  0.406983           0   \n",
       "4         0    0  0.395064 -0.474279 -0.473408 -0.499636           0   \n",
       "\n",
       "   Embarked_Q  Embarked_S  Embarked_n   ...     Pclass_2  Pclass_3  Cabin_A  \\\n",
       "0           0           1           0   ...            0         1        0   \n",
       "1           0           0           0   ...            0         0        0   \n",
       "2           0           1           0   ...            0         1        0   \n",
       "3           0           1           0   ...            0         0        0   \n",
       "4           0           1           0   ...            0         1        0   \n",
       "\n",
       "   Cabin_B  Cabin_C  Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_n  \n",
       "0        0        0        0        0        0        0        1  \n",
       "1        0        1        0        0        0        0        0  \n",
       "2        0        0        0        0        0        0        1  \n",
       "3        0        1        0        0        0        0        0  \n",
       "4        0        0        0        0        0        0        1  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dtrain = pd.read_csv('data/train.csv')\n",
    "raw_dtest = pd.read_csv('data/test.csv')\n",
    "dtrain, mean_train, std_train = process_data(raw_dtrain, training = True)\n",
    "print dtrain.isnull().sum()\n",
    "dtrain.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      29.754659\n",
       "SibSp     0.523008\n",
       "Parch     0.381594\n",
       "Fare     32.876990\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      13.277179\n",
       "SibSp     1.102743\n",
       "Parch     0.806057\n",
       "Fare     49.690114\n",
       "dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dtest, mean_train, std_train = process_data(raw_dtest, mean_train, std_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      29.754659\n",
       "SibSp     0.523008\n",
       "Parch     0.381594\n",
       "Fare     32.876990\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Age      13.277179\n",
       "SibSp     1.102743\n",
       "Parch     0.806057\n",
       "Fare     49.690114\n",
       "dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "std_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "      <th>Pclass_1</th>\n",
       "      <th>Pclass_2</th>\n",
       "      <th>Pclass_3</th>\n",
       "      <th>Cabin_A</th>\n",
       "      <th>Cabin_B</th>\n",
       "      <th>Cabin_C</th>\n",
       "      <th>Cabin_D</th>\n",
       "      <th>Cabin_E</th>\n",
       "      <th>Cabin_F</th>\n",
       "      <th>Cabin_G</th>\n",
       "      <th>Cabin_n</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.357406</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.504080</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1.298871</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.520767</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.428629</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.466682</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>-0.207473</td>\n",
       "      <td>-0.474279</td>\n",
       "      <td>-0.473408</td>\n",
       "      <td>-0.487310</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.584059</td>\n",
       "      <td>0.432550</td>\n",
       "      <td>0.767199</td>\n",
       "      <td>-0.414358</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex       Age     SibSp     Parch      Fare  Embarked_C  Embarked_Q  \\\n",
       "0    0  0.357406 -0.474279 -0.473408 -0.504080           0           1   \n",
       "1    1  1.298871  0.432550 -0.473408 -0.520767           0           0   \n",
       "2    0  2.428629 -0.474279 -0.473408 -0.466682           0           1   \n",
       "3    0 -0.207473 -0.474279 -0.473408 -0.487310           0           0   \n",
       "4    1 -0.584059  0.432550  0.767199 -0.414358           0           0   \n",
       "\n",
       "   Embarked_S  Pclass_1  Pclass_2  Pclass_3  Cabin_A  Cabin_B  Cabin_C  \\\n",
       "0           0         0         0         1        0        0        0   \n",
       "1           1         0         0         1        0        0        0   \n",
       "2           0         0         1         0        0        0        0   \n",
       "3           1         0         0         1        0        0        0   \n",
       "4           1         0         0         1        0        0        0   \n",
       "\n",
       "   Cabin_D  Cabin_E  Cabin_F  Cabin_G  Cabin_n  \n",
       "0        0        0        0        0        1  \n",
       "1        0        0        0        0        1  \n",
       "2        0        0        0        0        1  \n",
       "3        0        0        0        0        1  \n",
       "4        0        0        0        0        1  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_model(model, data, cv = 10):\n",
    "    X = data.drop(['Survived'], axis = 1)\n",
    "    y = data['Survived']\n",
    "    model.fit(X, y)\n",
    "    training = model.score(X, y)\n",
    "    validation = cross_validation.cross_val_score(model, X, y, cv=cv).mean()\n",
    "    print 'Training accuracy:\\t\\t\\t', training\n",
    "    print '%s-fold cross-validation accuracy:\\t' % cv, validation\n",
    "    print 'Delta(training - validation): \\t\\t', training - validation\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy:\t\t\t0.806958473625\n",
      "10-fold cross-validation accuracy:\t0.790257065032\n",
      "Delta(training - validation): \t\t0.0167014085928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=3, max_features='auto', max_leaf_nodes=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=300, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_model(RandomForestClassifier(n_estimators=300, max_depth=3), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on depth = 3=========\n",
      "Training accuracy:\t\t\t0.808080808081\n",
      "10-fold cross-validation accuracy:\t0.791380944274\n",
      "Delta(training - validation): \t\t0.0166998638066\n",
      "=========Test on depth = 4=========\n",
      "Training accuracy:\t\t\t0.848484848485\n",
      "10-fold cross-validation accuracy:\t0.818310634434\n",
      "Delta(training - validation): \t\t0.0301742140506\n",
      "=========Test on depth = 5=========\n",
      "Training accuracy:\t\t\t0.859708193042\n",
      "10-fold cross-validation accuracy:\t0.826126432868\n",
      "Delta(training - validation): \t\t0.0335817601735\n",
      "=========Test on depth = 6=========\n",
      "Training accuracy:\t\t\t0.870931537598\n",
      "10-fold cross-validation accuracy:\t0.830633299285\n",
      "Delta(training - validation): \t\t0.0402982383132\n",
      "=========Test on depth = 7=========\n",
      "Training accuracy:\t\t\t0.885521885522\n",
      "10-fold cross-validation accuracy:\t0.829559925094\n",
      "Delta(training - validation): \t\t0.0559619604283\n",
      "=========Test on depth = 8=========\n",
      "Training accuracy:\t\t\t0.910213243547\n",
      "10-fold cross-validation accuracy:\t0.830670752469\n",
      "Delta(training - validation): \t\t0.0795424910781\n",
      "=========Test on depth = 9=========\n",
      "Training accuracy:\t\t\t0.920314253648\n",
      "10-fold cross-validation accuracy:\t0.825065259335\n",
      "Delta(training - validation): \t\t0.0952489943127\n",
      "=========Test on depth = 10=========\n",
      "Training accuracy:\t\t\t0.94051627385\n",
      "10-fold cross-validation accuracy:\t0.826188571104\n",
      "Delta(training - validation): \t\t0.114327702745\n",
      "=========Test on depth = 11=========\n",
      "Training accuracy:\t\t\t0.951739618406\n",
      "10-fold cross-validation accuracy:\t0.821693905346\n",
      "Delta(training - validation): \t\t0.130045713061\n",
      "=========Test on depth = 12=========\n",
      "Training accuracy:\t\t\t0.961840628507\n",
      "10-fold cross-validation accuracy:\t0.817212291454\n",
      "Delta(training - validation): \t\t0.144628337053\n",
      "=========Test on depth = 13=========\n",
      "Training accuracy:\t\t\t0.967452300786\n",
      "10-fold cross-validation accuracy:\t0.817225059585\n",
      "Delta(training - validation): \t\t0.150227241201\n",
      "=========Test on depth = 14=========\n",
      "Training accuracy:\t\t\t0.971941638608\n",
      "10-fold cross-validation accuracy:\t0.81607649529\n",
      "Delta(training - validation): \t\t0.155865143318\n",
      "=========Test on depth = 15=========\n",
      "Training accuracy:\t\t\t0.973063973064\n",
      "10-fold cross-validation accuracy:\t0.812730677562\n",
      "Delta(training - validation): \t\t0.160333295502\n",
      "=========Test on depth = 16=========\n",
      "Training accuracy:\t\t\t0.978675645342\n",
      "10-fold cross-validation accuracy:\t0.807099931903\n",
      "Delta(training - validation): \t\t0.171575713439\n",
      "=========Test on depth = 17=========\n",
      "Training accuracy:\t\t\t0.983164983165\n",
      "10-fold cross-validation accuracy:\t0.811607082057\n",
      "Delta(training - validation): \t\t0.171557901108\n",
      "=========Test on depth = 18=========\n",
      "Training accuracy:\t\t\t0.985409652076\n",
      "10-fold cross-validation accuracy:\t0.80823629554\n",
      "Delta(training - validation): \t\t0.177173356537\n",
      "=========Test on depth = 19=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.807099931903\n",
      "Delta(training - validation): \t\t0.179432054629\n"
     ]
    }
   ],
   "source": [
    "for depth in np.arange(3,20,1): \n",
    "    print '=========Test on depth = %s=========' % depth\n",
    "    test_model(RandomForestClassifier(n_estimators=300, max_depth=depth), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on depth = 3=========\n",
      "Training accuracy:\t\t\t0.79797979798\n",
      "10-fold cross-validation accuracy:\t0.790332538872\n",
      "Delta(training - validation): \t\t0.00764725910793\n",
      "=========Test on depth = 4=========\n",
      "Training accuracy:\t\t\t0.837261503928\n",
      "10-fold cross-validation accuracy:\t0.803753546703\n",
      "Delta(training - validation): \t\t0.0335079572252\n",
      "=========Test on depth = 5=========\n",
      "Training accuracy:\t\t\t0.841750841751\n",
      "10-fold cross-validation accuracy:\t0.809334354784\n",
      "Delta(training - validation): \t\t0.032416486967\n",
      "=========Test on depth = 6=========\n",
      "Training accuracy:\t\t\t0.849607182941\n",
      "10-fold cross-validation accuracy:\t0.816038474634\n",
      "Delta(training - validation): \t\t0.0335687083065\n",
      "=========Test on depth = 7=========\n",
      "Training accuracy:\t\t\t0.861952861953\n",
      "10-fold cross-validation accuracy:\t0.817149585745\n",
      "Delta(training - validation): \t\t0.0448032762078\n",
      "=========Test on depth = 8=========\n",
      "Training accuracy:\t\t\t0.874298540965\n",
      "10-fold cross-validation accuracy:\t0.818285665645\n",
      "Delta(training - validation): \t\t0.05601287532\n",
      "=========Test on depth = 9=========\n",
      "Training accuracy:\t\t\t0.894500561167\n",
      "10-fold cross-validation accuracy:\t0.82390392691\n",
      "Delta(training - validation): \t\t0.0705966342577\n",
      "=========Test on depth = 10=========\n",
      "Training accuracy:\t\t\t0.905723905724\n",
      "10-fold cross-validation accuracy:\t0.821681988424\n",
      "Delta(training - validation): \t\t0.0840419173003\n",
      "=========Test on depth = 11=========\n",
      "Training accuracy:\t\t\t0.92480359147\n",
      "10-fold cross-validation accuracy:\t0.813841788673\n",
      "Delta(training - validation): \t\t0.110961802797\n",
      "=========Test on depth = 12=========\n",
      "Training accuracy:\t\t\t0.934904601571\n",
      "10-fold cross-validation accuracy:\t0.812743445693\n",
      "Delta(training - validation): \t\t0.122161155878\n",
      "=========Test on depth = 13=========\n",
      "Training accuracy:\t\t\t0.950617283951\n",
      "10-fold cross-validation accuracy:\t0.802655487459\n",
      "Delta(training - validation): \t\t0.147961796492\n",
      "=========Test on depth = 14=========\n",
      "Training accuracy:\t\t\t0.959595959596\n",
      "10-fold cross-validation accuracy:\t0.804852457156\n",
      "Delta(training - validation): \t\t0.15474350244\n",
      "=========Test on depth = 15=========\n",
      "Training accuracy:\t\t\t0.96632996633\n",
      "10-fold cross-validation accuracy:\t0.804852740892\n",
      "Delta(training - validation): \t\t0.161477225438\n",
      "=========Test on depth = 16=========\n",
      "Training accuracy:\t\t\t0.968574635241\n",
      "10-fold cross-validation accuracy:\t0.804902962206\n",
      "Delta(training - validation): \t\t0.163671673035\n",
      "=========Test on depth = 17=========\n",
      "Training accuracy:\t\t\t0.969696969697\n",
      "10-fold cross-validation accuracy:\t0.80376659857\n",
      "Delta(training - validation): \t\t0.165930371127\n",
      "=========Test on depth = 18=========\n",
      "Training accuracy:\t\t\t0.969696969697\n",
      "10-fold cross-validation accuracy:\t0.807124900692\n",
      "Delta(training - validation): \t\t0.162572069005\n",
      "=========Test on depth = 19=========\n",
      "Training accuracy:\t\t\t0.97418630752\n",
      "10-fold cross-validation accuracy:\t0.799272216547\n",
      "Delta(training - validation): \t\t0.174914090972\n"
     ]
    }
   ],
   "source": [
    "for depth in np.arange(3,20,1): \n",
    "    print '=========Test on depth = %s=========' % depth\n",
    "    test_model(ExtraTreesClassifier(n_estimators=300, max_depth=depth), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on depth = 3=========\n",
      "Training accuracy:\t\t\t0.810325476992\n",
      "10-fold cross-validation accuracy:\t0.792517024174\n",
      "Delta(training - validation): \t\t0.0178084528178\n",
      "=========Test on depth = 4=========\n",
      "Training accuracy:\t\t\t0.846240179574\n",
      "10-fold cross-validation accuracy:\t0.81047071842\n",
      "Delta(training - validation): \t\t0.0357694611534\n",
      "=========Test on depth = 5=========\n",
      "Training accuracy:\t\t\t0.859708193042\n",
      "10-fold cross-validation accuracy:\t0.828373623879\n",
      "Delta(training - validation): \t\t0.0313345691623\n",
      "=========Test on depth = 6=========\n",
      "Training accuracy:\t\t\t0.867564534231\n",
      "10-fold cross-validation accuracy:\t0.831756894791\n",
      "Delta(training - validation): \t\t0.0358076394406\n",
      "=========Test on depth = 7=========\n",
      "Training accuracy:\t\t\t0.881032547699\n",
      "10-fold cross-validation accuracy:\t0.835127681307\n",
      "Delta(training - validation): \t\t0.0459048663918\n",
      "=========Test on depth = 8=========\n",
      "Training accuracy:\t\t\t0.900112233446\n",
      "10-fold cross-validation accuracy:\t0.829521904438\n",
      "Delta(training - validation): \t\t0.0705903290079\n",
      "=========Test on depth = 9=========\n",
      "Training accuracy:\t\t\t0.920314253648\n",
      "10-fold cross-validation accuracy:\t0.827274713426\n",
      "Delta(training - validation): \t\t0.0930395402212\n",
      "=========Test on depth = 10=========\n",
      "Training accuracy:\t\t\t0.933782267116\n",
      "10-fold cross-validation accuracy:\t0.822780047668\n",
      "Delta(training - validation): \t\t0.111002219448\n",
      "=========Test on depth = 11=========\n",
      "Training accuracy:\t\t\t0.947250280584\n",
      "10-fold cross-validation accuracy:\t0.81943422994\n",
      "Delta(training - validation): \t\t0.127816050644\n",
      "=========Test on depth = 12=========\n",
      "Training accuracy:\t\t\t0.957351290685\n",
      "10-fold cross-validation accuracy:\t0.819446714334\n",
      "Delta(training - validation): \t\t0.13790457635\n",
      "=========Test on depth = 13=========\n",
      "Training accuracy:\t\t\t0.964085297419\n",
      "10-fold cross-validation accuracy:\t0.813841504937\n",
      "Delta(training - validation): \t\t0.150243792482\n",
      "=========Test on depth = 14=========\n",
      "Training accuracy:\t\t\t0.971941638608\n",
      "10-fold cross-validation accuracy:\t0.821681704687\n",
      "Delta(training - validation): \t\t0.150259933921\n",
      "=========Test on depth = 15=========\n",
      "Training accuracy:\t\t\t0.973063973064\n",
      "10-fold cross-validation accuracy:\t0.814977868573\n",
      "Delta(training - validation): \t\t0.158086104491\n",
      "=========Test on depth = 16=========\n",
      "Training accuracy:\t\t\t0.976430976431\n",
      "10-fold cross-validation accuracy:\t0.812692940642\n",
      "Delta(training - validation): \t\t0.163738035789\n",
      "=========Test on depth = 17=========\n",
      "Training accuracy:\t\t\t0.980920314254\n",
      "10-fold cross-validation accuracy:\t0.806001588923\n",
      "Delta(training - validation): \t\t0.174918725331\n",
      "=========Test on depth = 18=========\n",
      "Training accuracy:\t\t\t0.984287317621\n",
      "10-fold cross-validation accuracy:\t0.805988820792\n",
      "Delta(training - validation): \t\t0.178298496828\n",
      "=========Test on depth = 19=========\n",
      "Training accuracy:\t\t\t0.986531986532\n",
      "10-fold cross-validation accuracy:\t0.810458234026\n",
      "Delta(training - validation): \t\t0.176073752506\n"
     ]
    }
   ],
   "source": [
    "for depth in np.arange(3,20,1): \n",
    "    print '=========Test on depth = %s=========' % depth\n",
    "    test_model(RandomForestClassifier(n_estimators=300, max_depth=depth, criterion='entropy'), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=========Test on n_estimators = 100=========\n",
      "Training accuracy:\t\t\t0.892255892256\n",
      "10-fold cross-validation accuracy:\t0.830608614232\n",
      "Delta(training - validation): \t\t0.0616472780237\n",
      "=========Test on n_estimators = 150=========\n",
      "Training accuracy:\t\t\t0.90684624018\n",
      "10-fold cross-validation accuracy:\t0.830570593576\n",
      "Delta(training - validation): \t\t0.0762756466034\n",
      "=========Test on n_estimators = 200=========\n",
      "Training accuracy:\t\t\t0.919191919192\n",
      "10-fold cross-validation accuracy:\t0.828323402565\n",
      "Delta(training - validation): \t\t0.0908685166269\n",
      "=========Test on n_estimators = 250=========\n",
      "Training accuracy:\t\t\t0.933782267116\n",
      "10-fold cross-validation accuracy:\t0.824990069232\n",
      "Delta(training - validation): \t\t0.108792197884\n",
      "=========Test on n_estimators = 300=========\n",
      "Training accuracy:\t\t\t0.945005611672\n",
      "10-fold cross-validation accuracy:\t0.819359039837\n",
      "Delta(training - validation): \t\t0.125646571836\n",
      "=========Test on n_estimators = 350=========\n",
      "Training accuracy:\t\t\t0.953984287318\n",
      "10-fold cross-validation accuracy:\t0.821606514584\n",
      "Delta(training - validation): \t\t0.132377772734\n",
      "=========Test on n_estimators = 400=========\n",
      "Training accuracy:\t\t\t0.960718294052\n",
      "10-fold cross-validation accuracy:\t0.818235728067\n",
      "Delta(training - validation): \t\t0.142482565984\n",
      "=========Test on n_estimators = 450=========\n",
      "Training accuracy:\t\t\t0.961840628507\n",
      "10-fold cross-validation accuracy:\t0.820495687209\n",
      "Delta(training - validation): \t\t0.141344941298\n",
      "=========Test on n_estimators = 500=========\n",
      "Training accuracy:\t\t\t0.962962962963\n",
      "10-fold cross-validation accuracy:\t0.819372091704\n",
      "Delta(training - validation): \t\t0.143590871259\n",
      "=========Test on n_estimators = 550=========\n",
      "Training accuracy:\t\t\t0.962962962963\n",
      "10-fold cross-validation accuracy:\t0.819372091704\n",
      "Delta(training - validation): \t\t0.143590871259\n",
      "=========Test on n_estimators = 600=========\n",
      "Training accuracy:\t\t\t0.964085297419\n",
      "10-fold cross-validation accuracy:\t0.817124900692\n",
      "Delta(training - validation): \t\t0.146960396726\n",
      "=========Test on n_estimators = 650=========\n",
      "Training accuracy:\t\t\t0.96632996633\n",
      "10-fold cross-validation accuracy:\t0.816001305187\n",
      "Delta(training - validation): \t\t0.150328661143\n"
     ]
    }
   ],
   "source": [
    "for n in np.arange(100,700,50): \n",
    "    print '=========Test on n_estimators = %s=========' % n\n",
    "    test_model(GradientBoostingClassifier(n_estimators=n), dtrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
    "                     'C': [1, 10, 100, 1000]},\n",
    "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
    "Xtrain = dtrain.drop(['Survived'], axis = 1)\n",
    "ytrain = dtrain['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf = GridSearchCV(SVC(C=1), tuned_parameters, cv=5)\n",
    "clf.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
