{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Basic\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "\n",
    "# Data Analysis Specific\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from dateutil.parser import parse as date_parser\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "# Marchine Learning Specific\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.grid_search import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "# IPython magic\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200 400 0.5\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = './data/'\n",
    "DETROIT_LAT = (42.252, 42.452)\n",
    "DETROIT_LNG = (-83.295, -82.895)\n",
    "SIZE_RATIO = 1000\n",
    "DETROIT_WIDTH = 200\n",
    "DETROIT_HEIGHT = 400\n",
    "print DETROIT_WIDTH, DETROIT_HEIGHT, float(DETROIT_WIDTH)/DETROIT_HEIGHT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "raw_violation = pd.read_csv(DATA_PATH + 'detroit-blight-violations.csv', low_memory=False)\n",
    "raw_311 = pd.read_csv(DATA_PATH + 'detroit-311.csv', low_memory=False)\n",
    "raw_crime = pd.read_csv(DATA_PATH + 'detroit-crime.csv', low_memory=False)\n",
    "raw_permit = pd.read_csv(DATA_PATH + 'detroit-demolition-permits.tsv.csv', low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_date_parser(dt):\n",
    "    try:\n",
    "        return date_parser(dt)\n",
    "    except:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean again permit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_permit = pd.read_csv('clean/permit.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_permit['addr'] = raw_permit['SITE_ADDRESS']\n",
    "clean_permit['turst'] = True\n",
    "miss_permit_idx = clean_permit[['lat','lng']].isnull()[clean_permit.isnull()].dropna().index\n",
    "clean_permit['turst'].ix[miss_permit_idx] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_permit.to_csv('clean/permit.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_permit = pd.read_csv('clean/permit.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def clean_again(df):\n",
    "    assert df['lat'].isnull().sum() == df['lng'].isnull().sum(), 'input: lat(%d) and lng(%d) must be equal' % (df['lat'].isnull().sum(), df['lng'].isnull().sum())\n",
    "    to_clean = df[df['turst']==False].copy()\n",
    "    print 'Remain:', (to_clean['turst'] == False).sum()\n",
    "    tursted = df[df['turst']==True].copy()\n",
    "    geolocator = Nominatim()\n",
    "    for idx in to_clean.index:\n",
    "        addr = to_clean.loc[idx,'addr'] + ', Detroit'\n",
    "        try:\n",
    "            loc = geolocator.geocode(addr) \n",
    "            if loc is None:\n",
    "                print 'Cannot parse %s' % addr\n",
    "            else:\n",
    "                lat, lng = float(loc.latitude), float(loc.longitude)\n",
    "                if lat is not None and lng is not None:\n",
    "                    to_clean.loc[idx,'lat'] = lat\n",
    "                    to_clean.loc[idx,'lng'] = lng\n",
    "            to_clean.loc[idx,'turst'] = True\n",
    "        except Exception as e:\n",
    "            print 'Exception: %s, maybe service time out.' % e\n",
    "            break\n",
    "    print 'Remain:', (to_clean['turst'] == False).sum()\n",
    "    res = pd.concat([tursted, to_clean]).sort_index()\n",
    "    assert res['lat'].isnull().sum() == res['lng'].isnull().sum(), 'output: lat(%d) and lng(%d) must be equal' % (res['lat'].isnull().sum(), res['lng'].isnull().sum())\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain: 202\n",
      "Exception: Service timed out, maybe service time out.\n",
      "Remain: 202\n"
     ]
    }
   ],
   "source": [
    "clean_permit = clean_again(clean_permit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_permit.to_csv('clean/permit.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean again violation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def violation_lat_lng():\n",
    "    lat_lng = raw_violation['ViolationAddress'].map(lambda x: x.split('\\n')[-1][1:-1])\n",
    "    lat = lat_lng.map(lambda x: float(x.split(',')[0]))\n",
    "    lng = lat_lng.map(lambda x: float(x.split(',')[1]))\n",
    "    addr = pd.DataFrame()\n",
    "    addr['lat'] = lat\n",
    "    addr['lng'] = lng\n",
    "    addr = addr.apply(lambda x: None if 42.331<=x.lat<42.332 and -83.048<=x.lng<-83.047 else x, axis = 1)\n",
    "    addr['turst'] = True\n",
    "    miss_idx = addr[['lat','lng']].isnull()[addr.isnull()].dropna().index\n",
    "    addr['turst'].ix[miss_idx] = False\n",
    "    addr['addr'] = raw_violation['ViolationAddress'].map(lambda x: x.split('\\n')[0])\n",
    "    addr['date'] = raw_violation['TicketIssuedDT'].map(lambda x: my_date_parser(x))\n",
    "\n",
    "    return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_violation = violation_lat_lng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307804 entries, 0 to 307803\n",
      "Data columns (total 5 columns):\n",
      "lat      286685 non-null float64\n",
      "lng      286685 non-null float64\n",
      "turst    307804 non-null bool\n",
      "addr     307804 non-null object\n",
      "date     268950 non-null object\n",
      "dtypes: bool(1), float64(2), object(2)\n",
      "memory usage: 9.7+ MB\n"
     ]
    }
   ],
   "source": [
    "clean_violation.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_violation.to_csv('clean/violation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_violation = pd.read_csv('clean/violation.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain: 21048\n",
      "Time out, Service timed out\n",
      "Remain: 21048\n"
     ]
    }
   ],
   "source": [
    "clean_violation = clean_again(clean_violation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_violation.to_csv('clean/violation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp = raw_violation['JudgmentAmt'].map(lambda x: float(x[1:]) if str(x)[0] == '$' else float(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tmp.ix[tmp.isnull()] = 140."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_violation['JudgeAmt'] = tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_violation.to_csv('clean/violation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remain: 21033\n",
      "Cannot parse 657 MULLETT, Detroit\n",
      "Cannot parse 312 WEST END, Detroit\n",
      "Cannot parse 15326 G A, Detroit\n",
      "Cannot parse 260 SCHWEITZER PL, Detroit\n",
      "Cannot parse 260 SCHWEITZER PL, Detroit\n",
      "Cannot parse 260 SCHWEITZER PL, Detroit\n",
      "Cannot parse 260 SCHWEITZER PL, Detroit\n",
      "Exception: Service timed out, maybe service time out.\n",
      "Remain: 20919\n"
     ]
    }
   ],
   "source": [
    "clean_violation = clean_again(clean_violation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clean_violation.to_csv('clean/violation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# clean 311 call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def three11_lat_lng():\n",
    "    lat = raw_311['lat'].map(lambda x: float(x))\n",
    "    lng = raw_311['lng'].map(lambda x: float(x))\n",
    "    addr = pd.DataFrame()\n",
    "    addr['lat'] = lat\n",
    "    addr['lng'] = lng\n",
    "    type_convert = {'Graffiti Abatement (internal use only, public issue)': 16, 'Customer Service (internal use only, private issue)': 14, 'Abandoned Vehicle': 4, 'DPW - Debris Removal': 17, 'Curbside Solid Waste Issue': 20, 'Trash Issue - Bulk waste deposited more than 24 hours before designated time': 19, 'Trash Issue - Improper placement of refuse container between collections/left at curbside': 18, 'Running Water in a Home or Building': 10, 'Clogged Drain': 0, 'Residential Snow Removal Issue': 15, 'Illegal Dumping / Illegal Dump Sites': 9, 'Water Main Break': 3, 'Traffic Sign Issue': 8, 'Test (internal use only, public issue)': 12, 'Manhole Cover Issue': 2, 'DPW - Other environmental': 22, 'Traffic Signal Issue': 6, 'Tree Issue': 1, 'Detroit Land Bank Referral': 21, 'Graffiti': 13, 'Street Light Pole Down': 11, 'Potholes': 7, 'Fire Hydrant Issue': 5}\n",
    "    addr['Category'] = raw_311['issue_type'].map(lambda key: type_convert[key])\n",
    "    addr['date'] = raw_311['ticket_last_updated_date_time'].map(lambda x: my_date_parser(x))\n",
    "    return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_311 = three11_lat_lng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_311.to_csv('clean/311.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22], dtype=int64)"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_311.Category.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clean crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def crime_lat_lng():\n",
    "    lat = raw_crime['LAT'].map(lambda x: float(x))\n",
    "    lng = raw_crime['LON'].map(lambda x: float(x))\n",
    "    addr = pd.DataFrame()\n",
    "    addr['lat'] = lat\n",
    "    addr['lng'] = lng\n",
    "    category_convert = {'CONGRESS': 42, 'LIQUOR': 34, 'IMMIGRATION': 41, 'ENVIRONMENT': 28, 'FRAUD': 10, 'AGGRAVATED ASSAULT': 6, 'ROBBERY': 9, 'BURGLARY': 5, 'STOLEN PROPERTY': 25, 'OTHER BURGLARY': 24, 'HOMICIDE': 13, 'OBSCENITY': 36, 'MISCELLANEOUS ARREST': 48, 'TAX REVENUE': 38, 'JUSTIFIABLE HOMICIDE': 43, 'ANTITRUST': 32, 'ASSAULT': 0, 'FELONY DEATH FROM FLEEING VEHICLE': 47, 'WEAPONS OFFENSES': 3, 'KIDNAPING': 22, 'TRAFFIC VIOLATIONS-DRIVING ON SUSPENDED': 8, 'ELECTION LAWS': 45, 'GAMBLING': 40, 'VAGRANCY (OTHER)': 27, 'OBSTRUCTING THE POLICE': 19, 'DRUNKENNESS': 46, 'OBSTRUCTING JUDICIARY': 11, 'DANGEROUS DRUGS': 12, 'STOLEN VEHICLE': 2, 'REVOKED': 44, 'ARSON': 17, 'DAMAGE TO PROPERTY': 7, 'FAMILY OFFENSE': 16, 'LARCENY': 1, 'HEALTH-SAFETY': 26, 'OUIL DISPOSE OF VEHICLE TO AVOID FORFEITURE': 15, 'ESCAPE': 18, 'SOVEREIGNTY': 37, 'NEGLIGENT HOMICIDE': 39, 'EMBEZZLEMENT': 29, 'SOLICITATION': 14, 'FORGERY': 30, 'OUIL': 35, 'PUBLIC PEACE': 33, 'EXTORTION': 23, 'BRIBERY': 21, 'TRAFFIC VIOLATIONS-MOTORCYCLE VIOLATIONS': 4, 'MILITARY': 49, 'CONSPIRACY BY COMPUTER': 31, 'RUNAWAY': 20}\n",
    "    addr['Category'] = raw_crime['CATEGORY'].map(lambda key: category_convert[key])\n",
    "    addr['date'] = raw_crime['INCIDENTDATE'].map(lambda x: my_date_parser(x))\n",
    "    return addr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_crime = crime_lat_lng()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clean_crime.to_csv('clean/crime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33,\n",
       "       34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49], dtype=int64)"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_crime.Category.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
