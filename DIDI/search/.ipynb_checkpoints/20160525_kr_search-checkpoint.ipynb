{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "from six.moves import cPickle as pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as skStandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "\n",
    "PATH = '../season_1/'\n",
    "CLEAN_PATH = PATH+'clean/'\n",
    "\n",
    "from mylib import myStandardScaler,process_order,process_traffic,get_order_group,get_traffic_group,XY_order_traffic, prediction2submit, Search_Model, DISTRICTS\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(CLEAN_PATH+'cluster_map.csv',index_col=0)\n",
    "poi = pd.read_csv(CLEAN_PATH+'poi.csv',index_col=0)\n",
    "train_order_group = pd.read_pickle(CLEAN_PATH+'train_order_group.pickle')\n",
    "test_order_group = pd.read_pickle(CLEAN_PATH+'test_order_group.pickle')\n",
    "train_traffic_group = pd.read_pickle(CLEAN_PATH+'train_traffic_group.pickle')\n",
    "test_traffic_group = pd.read_pickle(CLEAN_PATH+'test_traffic_group.pickle')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_slot = pd.Index(sorted(train_order_group.values()[0].index.unique()))\n",
    "train_slot = pd.Index(filter(lambda x: x%1000 >4,train_slot))\n",
    "test_slot = test_target['datetimeslot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take 00:00:16\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "train_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    train_XY_group[district] = XY_order_traffic(district,train_order_group,train_traffic_group,train_slot)\n",
    "test_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    test_XY_group[district] = XY_order_traffic(district,test_order_group,test_traffic_group,test_slot)\n",
    "for district in DISTRICTS:\n",
    "    scaler = myStandardScaler()\n",
    "    train_XY_group[district][0] = scaler.fit_transform(train_XY_group[district][0])\n",
    "    test_XY_group[district][0] = scaler.transform(test_XY_group[district][0])\n",
    "    \n",
    "stop = time.time()\n",
    "print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 2350be163432e42270d2670cb3c02f80...\n",
      "Best Params: {'kernel': 'rbf', 'degree': 6, 'gamma': 0.0011837764395687955, 'alpha': 3.9216704069560593}\n",
      "CV score: 0.224600884762\n",
      "Fit (R2) score: 0.174174973418\n",
      "The metrics: 0.220644581466\n",
      "Take 00:08:20\n",
      "Searching 4b7f6f4e2bf237b6cc58f57142bea5c0...\n",
      "Best Params: {'kernel': 'rbf', 'degree': 6, 'gamma': 0.0011837764395687955, 'alpha': 4.8924407615173449}\n",
      "CV score: 0.182725130397\n",
      "Fit (R2) score: 0.110860376755\n",
      "The metrics: 0.1807855509\n",
      "Take 00:08:53\n",
      "Searching 82cc4851f9e4faa4e54309f8bb73fd7c...\n",
      "Best Params: {'kernel': 'rbf', 'degree': 8, 'gamma': 0.1173208643541308, 'alpha': 3.9216704069560593}\n",
      "CV score: 0.957579224288\n",
      "Fit (R2) score: 0.2535138247\n",
      "The metrics: 0.745626587978\n",
      "Take 00:08:27\n",
      "Searching 74ec84f1cf75cf89ae176c8c6ceec5ba...\n",
      "Best Params: {'kernel': 'rbf', 'degree': 9, 'gamma': 0.0011837764395687955, 'alpha': 2.5197770802454351}\n",
      "CV score: 0.16742661744\n",
      "Fit (R2) score: 0.178314721018\n",
      "The metrics: 0.16310846817\n",
      "Take 00:08:48\n",
      "Searching b05379ac3f9b7d99370d443cfd5dcc28...\n",
      "Best Params: {'kernel': 'rbf', 'degree': 9, 'gamma': 0.1173208643541308, 'alpha': 3.9216704069560593}\n",
      "CV score: 0.902599416523\n",
      "Fit (R2) score: 0.255797058067\n",
      "The metrics: 0.719381485256\n",
      "Take 00:08:43\n",
      "Searching 2920ece99323b4c111d6f9affc7ea034...\n",
      "Best Params: {'kernel': 'rbf', 'degree': 2, 'gamma': 0.11118239115586903, 'alpha': 3.9216704069560593}\n",
      "CV score: 0.747872808366\n",
      "Fit (R2) score: 0.278995199648\n",
      "The metrics: 0.601333518277\n",
      "Take 00:09:11\n",
      "Searching 7f84bdfc2b6d4541e1f6c0a3349e0251...\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 1118, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 300, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"C:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.py\", line 345, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"C:\\Anaconda2\\lib\\inspect.py\", line 1049, in getinnerframes\n",
      "    framelist.append((tb.tb_frame,) + getframeinfo(tb, context))\n",
      "  File \"C:\\Anaconda2\\lib\\inspect.py\", line 1009, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"C:\\Anaconda2\\lib\\inspect.py\", line 454, in getsourcefile\n",
      "    if hasattr(getmodule(object, filename), '__loader__'):\n",
      "  File \"C:\\Anaconda2\\lib\\inspect.py\", line 497, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"C:\\Anaconda2\\lib\\inspect.py\", line 460, in getabsfile\n",
      "    def getabsfile(object, _filename=None):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "\n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "string index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_code\u001b[1;34m(self, code_obj, result)\u001b[0m\n\u001b[0;32m   2900\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2901\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_in_exec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2902\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2903\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2904\u001b[0m             \u001b[0moutflag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mshowtraceback\u001b[1;34m(self, exc_tuple, filename, tb_offset, exception_only)\u001b[0m\n\u001b[0;32m   1828\u001b[0m                     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1829\u001b[0m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[1;32m-> 1830\u001b[1;33m                                             value, tb, tb_offset=tb_offset)\n\u001b[0m\u001b[0;32m   1831\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1832\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_showtraceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1390\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1391\u001b[0m         return FormattedTB.structured_traceback(\n\u001b[1;32m-> 1392\u001b[1;33m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[0m\u001b[0;32m   1393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1298\u001b[0m             \u001b[1;31m# Verbose modes need a full traceback\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m             return VerboseTB.structured_traceback(\n\u001b[1;32m-> 1300\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0metype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1301\u001b[0m             )\n\u001b[0;32m   1302\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\ultratb.pyc\u001b[0m in \u001b[0;36mstructured_traceback\u001b[1;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[0;32m   1182\u001b[0m                 \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m             \u001b[0mstructured_traceback_parts\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mformatted_exception\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mstructured_traceback_parts\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: string index out of range"
     ]
    }
   ],
   "source": [
    "all_now = time.time()\n",
    "\n",
    "grid_params = {'kernel': ['poly','rbf'],'alpha': 0.01 * np.logspace(0, 7, 30, base = 2.5), 'degree': np.arange(2, 10),'gamma': np.random.random(20)%0.12}\n",
    "\n",
    "# grid_params = {'n_estimators': [100] ,'max_depth': [1], 'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "search_models = {district: Search_Model(KernelRidge) for district in DISTRICTS}\n",
    "test_prediction = dict()\n",
    "for district, model in search_models.items()[::-1]:\n",
    "    now = time.time()\n",
    "    print 'Searching %s...'%district\n",
    "    model.fit(grid_params,*train_XY_group[district])\n",
    "    test_prediction[district] = model.predict(test_XY_group[district][0]) - test_XY_group[district][1].fillna(0)\n",
    "    with open('kr/test_prediction_%s.pickle'%(district),'wb') as f:\n",
    "        pickle.dump(test_prediction[district],f)\n",
    "    stop = time.time()\n",
    "    print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)\n",
    "    \n",
    "all_stop = time.time()\n",
    "print 'Totally take %02d:%02d:%02d' % ((all_stop-all_now)/3600,(all_stop-all_now)/60,(all_stop-all_now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "all_now = time.time()\n",
    "\n",
    "grid_params = {'kernel': ['rbf'],'alpha': np.random.rand(300) * 7 + 0.5,'gamma': np.random.random(20)%0.12}\n",
    "\n",
    "# grid_params = {'n_estimators': [100] ,'max_depth': [1], 'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "search_models = {district: Search_Model(KernelRidge) for district in DISTRICTS}\n",
    "test_prediction = dict()\n",
    "for district, model in search_models.items()[::-1]:\n",
    "    now = time.time()\n",
    "    print 'Searching %s...'%district\n",
    "    model.fit(grid_params,*train_XY_group[district])\n",
    "    test_prediction[district] = model.predict(test_XY_group[district][0]) - test_XY_group[district][1].fillna(0)\n",
    "    with open('kr/test_prediction_%s.pickle'%(district),'wb') as f:\n",
    "        pickle.dump(test_prediction[district],f)\n",
    "    stop = time.time()\n",
    "    print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)\n",
    "    \n",
    "all_stop = time.time()\n",
    "print 'Totally take %02d:%02d:%02d' % ((all_stop-all_now)/3600,(all_stop-all_now)/60,(all_stop-all_now)%60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
