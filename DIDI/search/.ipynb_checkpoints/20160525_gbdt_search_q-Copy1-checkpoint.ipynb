{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "from six.moves import cPickle as pickle\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as skStandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "\n",
    "PATH = 'season_1/'\n",
    "CLEAN_PATH = PATH+'clean/'\n",
    "\n",
    "from mylib import myStandardScaler,process_order,process_traffic,get_order_group,get_traffic_group,XY_order_traffic, prediction2submit, Search_Model, DISTRICTS\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(CLEAN_PATH+'cluster_map.csv',index_col=0)\n",
    "poi = pd.read_csv(CLEAN_PATH+'poi.csv',index_col=0)\n",
    "train_order_group = pd.read_pickle(CLEAN_PATH+'train_order_group.pickle')\n",
    "test_order_group = pd.read_pickle(CLEAN_PATH+'test_order_group.pickle')\n",
    "train_traffic_group = pd.read_pickle(CLEAN_PATH+'train_traffic_group.pickle')\n",
    "test_traffic_group = pd.read_pickle(CLEAN_PATH+'test_traffic_group.pickle')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_slot = pd.Index(sorted(train_order_group.values()[0].index.unique()))\n",
    "train_slot = pd.Index(filter(lambda x: x%1000 >4,train_slot))\n",
    "test_slot = test_target['datetimeslot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take 00:00:16\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "train_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    train_XY_group[district] = XY_order_traffic(district,train_order_group,train_traffic_group,train_slot)\n",
    "test_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    test_XY_group[district] = XY_order_traffic(district,test_order_group,test_traffic_group,test_slot)\n",
    "for district in DISTRICTS:\n",
    "    scaler = myStandardScaler()\n",
    "    train_XY_group[district][0] = scaler.fit_transform(train_XY_group[district][0])\n",
    "    test_XY_group[district][0] = scaler.transform(test_XY_group[district][0])\n",
    "    \n",
    "stop = time.time()\n",
    "print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching 2350be163432e42270d2670cb3c02f80...\n",
      "Best Params: {'max_features': 'log2', 'n_estimators': 444, 'max_depth': 1}\n",
      "CV score: 0.228307556511\n",
      "Fit (R2) score: 0.290810437715\n",
      "The metrics: 0.211989941949\n",
      "Take 00:00:25\n",
      "Searching 4b7f6f4e2bf237b6cc58f57142bea5c0...\n",
      "Best Params: {'max_features': None, 'n_estimators': 444, 'max_depth': 1}\n",
      "CV score: 0.212946941494\n",
      "Fit (R2) score: 0.316536431194\n",
      "The metrics: 0.187595682667\n",
      "Take 00:00:31\n",
      "Searching 82cc4851f9e4faa4e54309f8bb73fd7c...\n"
     ]
    }
   ],
   "source": [
    "all_now = time.time()\n",
    "\n",
    "grid_params = {'n_estimators': [444] ,'max_depth': [1,2,3], 'max_features': ['log2',None]}\n",
    "\n",
    "# grid_params = {'n_estimators': [100] ,'max_depth': [1], 'max_features': ['log2', 'sqrt']}\n",
    "\n",
    "search_models = {district: Search_Model(GradientBoostingRegressor) for district in DISTRICTS}\n",
    "test_prediction = dict()\n",
    "for district, model in search_models.items()[::-1]:\n",
    "    now = time.time()\n",
    "    print 'Searching %s...'%district\n",
    "    model.fit(grid_params,*train_XY_group[district])\n",
    "    test_prediction[district] = model.predict(test_XY_group[district][0]) - test_XY_group[district][1].fillna(0)\n",
    "    with open(CLEAN_PATH+'prediction_gdbt_q/test_prediction_%s.pickle'%(district),'wb') as f:\n",
    "        pickle.dump(test_prediction[district],f)\n",
    "    stop = time.time()\n",
    "    print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)\n",
    "    \n",
    "all_stop = time.time()\n",
    "print 'Totally take %02d:%02d:%02d' % ((all_stop-all_now)/3600,(all_stop-all_now)/60,(all_stop-all_now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
