{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dateutil.parser import parse as dateutil_parse\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler as skStandardScaler\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor, ExtraTreesRegressor\n",
    "from sklearn.cross_validation import train_test_split,cross_val_score\n",
    "\n",
    "PATH = 'season_1/'\n",
    "CLEAN_PATH = PATH+'clean/'\n",
    "\n",
    "from mylib import myStandardScaler,process_order,process_traffic,get_order_group,get_traffic_group,XY_order_traffic, prediction2submit, Search_Model, DISTRICTS\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cluster_map = pd.read_csv(CLEAN_PATH+'cluster_map.csv',index_col=0)\n",
    "poi = pd.read_csv(CLEAN_PATH+'poi.csv',index_col=0)\n",
    "train_order = pd.read_pickle(CLEAN_PATH+'train_order.pickle')\n",
    "test_order = pd.read_pickle(CLEAN_PATH+'test_order.pickle')\n",
    "train_traffic = pd.read_pickle(CLEAN_PATH+'train_traffic.pickle')\n",
    "test_traffic = pd.read_pickle(CLEAN_PATH+'test_traffic.pickle')\n",
    "train_weather = pd.read_pickle(CLEAN_PATH+'train_weather.pickle')\n",
    "test_weather = pd.read_pickle(CLEAN_PATH+'test_weather.pickle')\n",
    "test_target = pd.read_csv(CLEAN_PATH+'test_target.csv',index_col=0,parse_dates=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take 00:19:16\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "train_order = process_order(train_order)\n",
    "test_order = process_order(test_order)\n",
    "train_traffic = process_traffic(train_traffic)\n",
    "test_traffic = process_traffic(test_traffic)\n",
    "\n",
    "train_order_group = get_order_group(train_order)\n",
    "test_order_group = get_order_group(test_order)\n",
    "train_traffic_group = get_traffic_group(train_traffic)\n",
    "test_traffic_group = get_traffic_group(test_traffic)\n",
    "\n",
    "train_slot = pd.Index(sorted(train_order['datetimeslot'].unique()))\n",
    "train_slot = pd.Index(filter(lambda x: x%1000 >4,train_slot))\n",
    "test_slot = test_target['datetimeslot']\n",
    "\n",
    "stop = time.time()\n",
    "print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Take 00:00:19\n"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "\n",
    "train_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    train_XY_group[district] = XY_order_traffic(district,train_order_group,train_traffic_group,train_slot)\n",
    "test_XY_group = dict()\n",
    "for district in DISTRICTS:\n",
    "    test_XY_group[district] = XY_order_traffic(district,test_order_group,test_traffic_group,test_slot)\n",
    "for district in DISTRICTS:\n",
    "    scaler = myStandardScaler()\n",
    "    train_XY_group[district][0] = scaler.fit_transform(train_XY_group[district][0])\n",
    "    test_XY_group[district][0] = scaler.transform(test_XY_group[district][0])\n",
    "    \n",
    "stop = time.time()\n",
    "print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "the_scorer = make_scorer(mymetrics,greater_is_better=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83046714 -0.81149442 -0.87328421]\n",
      "0.838415255249\n",
      "0.0258440710689\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':12}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83892389 -0.85266232 -0.86648345]\n",
      "0.852689886364\n",
      "0.0112511601004\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':8}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83138623 -0.79353353 -0.87784487]\n",
      "0.834254877388\n",
      "0.0344796778876\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':14}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.83754856 -0.79839981 -0.86636178]\n",
      "0.834103383561\n",
      "0.0278521018729\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':16}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84747325 -0.79683217 -0.88360061]\n",
      "0.842635345673\n",
      "0.035587866549\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':20}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.84091984 -0.82700419 -0.90147296]\n",
      "0.856465662879\n",
      "0.0323280491496\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':None}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(ExtraTreesRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.91380375 -0.80811523 -0.83499188]\n",
      "0.852303616713\n",
      "0.0448500318359\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':15}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(ExtraTreesRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.91519035 -0.78509206 -0.83041531]\n",
      "0.843565908188\n",
      "0.0539202807956\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':20}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(ExtraTreesRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.90858172 -0.82475439 -0.84563716]\n",
      "0.859657760219\n",
      "0.0356294646107\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'min_samples_split':4}\n",
    "trainX, trainY = train_XY_group.values()[0]\n",
    "scores = cross_val_score(ExtraTreesRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.56030667 -0.5075259  -0.56756581]\n",
      "0.545132796257\n",
      "0.0267567128962\n"
     ]
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':16}\n",
    "trainX, trainY = train_XY_group.values()[7]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20160101005     1.0\n",
       "20160101006     2.0\n",
       "20160101007     0.0\n",
       "20160101008     0.0\n",
       "20160101009     1.0\n",
       "20160101010     1.0\n",
       "20160101011     0.0\n",
       "20160101012     0.0\n",
       "20160101013     1.0\n",
       "20160101014     1.0\n",
       "20160101015     1.0\n",
       "20160101016     7.0\n",
       "20160101017     5.0\n",
       "20160101018     8.0\n",
       "20160101019     2.0\n",
       "20160101020     4.0\n",
       "20160101021     7.0\n",
       "20160101022     6.0\n",
       "20160101023     0.0\n",
       "20160101024     3.0\n",
       "20160101025    14.0\n",
       "20160101026     8.0\n",
       "20160101027     6.0\n",
       "20160101028     0.0\n",
       "20160101029     2.0\n",
       "20160101030     4.0\n",
       "20160101031     4.0\n",
       "20160101032     1.0\n",
       "20160101033     0.0\n",
       "20160101034     2.0\n",
       "               ... \n",
       "20160121115     1.0\n",
       "20160121116     1.0\n",
       "20160121117     0.0\n",
       "20160121118     1.0\n",
       "20160121119     2.0\n",
       "20160121120     2.0\n",
       "20160121121     1.0\n",
       "20160121122     0.0\n",
       "20160121123     3.0\n",
       "20160121124     3.0\n",
       "20160121125     4.0\n",
       "20160121126     5.0\n",
       "20160121127     3.0\n",
       "20160121128     1.0\n",
       "20160121129     2.0\n",
       "20160121130     6.0\n",
       "20160121131     2.0\n",
       "20160121132     1.0\n",
       "20160121133     2.0\n",
       "20160121134     2.0\n",
       "20160121135     3.0\n",
       "20160121136     3.0\n",
       "20160121137     0.0\n",
       "20160121138     0.0\n",
       "20160121139     1.0\n",
       "20160121140     2.0\n",
       "20160121141     6.0\n",
       "20160121142     1.0\n",
       "20160121143     4.0\n",
       "20160121144     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': 111, 'max_depth':16}\n",
    "trainX, trainY = train_XY_group.values()[7]\n",
    "scores = cross_val_score(RandomForestRegressor(**params), trainX, trainY, scoring=the_scorer)\n",
    "print scores\n",
    "print -np.mean(scores)\n",
    "print np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "grid_params = {'n_estimators': [120] ,'max_depth': np.arange(10, 18), 'min_samples_leaf': [2, 6, 10], \n",
    "                     'min_samples_split': [2, 6, 10], 'max_features': ['log2', 'sqrt', None]}\n",
    "trainX, trainY = train_XY_group.values()[7]\n",
    "rfr_searcher = Search_Model(RandomForestRegressor)\n",
    "rfr_searcher.fit(grid_params, trainX, trainY)\n",
    "rfr_searcher.predict(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# grid_params = {'n_estimators': [150] ,'max_depth': np.arange(8, 18), 'min_samples_leaf': [2, 6, 10], \n",
    "#                      'min_samples_split': [2, 6, 10], 'bootstrap': [True, False], 'max_features': ['log2', 'sqrt', None]}\n",
    "# search_models = {district: Search_Model(RandomForestRegressor) for district in DISTRICTS}\n",
    "# test_prediction = dict()\n",
    "# for district, model in search_models.items():\n",
    "#     now = time.time()\n",
    "#     print 'Searching %s...'%district\n",
    "#     model.fit(grid_params,*train_XY_group[district])\n",
    "# #     train_prediction = pd.Series(np.floor(model.predict(train_XY_group[district][0])),index=train_XY_group[district][1].index)\n",
    "#     test_prediction[district] = model.predict(test_XY_group[district][0]) - test_XY_group[district][1].fillna(0)\n",
    "# #     print 'r2 score', model.score(*train_XY_group[district])\n",
    "# #     print distri'metric', metrics(model.predict(train_XY_group[district][0]),train_prediction)\n",
    "#     stop = time.time()\n",
    "#     print 'Take %02d:%02d:%02d' % ((stop-now)/3600,(stop-now)/60,(stop-now)%60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
